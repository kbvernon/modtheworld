[["index.html", "Modeling the World with R Welcome", " Modeling the World with R Kenneth Blake Vernon 2021-02-12 Welcome This is the website for “Modeling the World with R”, a bookdown project for a university course that introduces students to the fundamentals of statistics and statistical programming in R. While geared toward practical applications, like analyzing and visualizing data, this book aims to promote higher-order understanding of statistical concepts and theory too - not just the how, but the why. The reader will, thus, come away with a better sense of statistical relevance; meaning, they will be able to start with a scientific question, translate it into a more precise statistical form, identify the appropriate statistical methods, and then use the statistical programming tools offered by R to implement those methods efficiently. In a word, then, the book aims to make the reader a more efficient and more thoughtful empirical modeler. The R source code for this bookdown website may be found at github.com/kbvernon/modtheworld. Continuous integration and rendering is maintained with Github Actions. You can see its current ‘build status’ with the following Github badge: How to contribute? Probably the easiest way to contribute is to submit an issue or pull request to the Github page. Please note, however, that by contributing to Modeling the World, you agree to follow its Contributor Code of Conduct. "],["acknowledgments.html", "Acknowledgments", " Acknowledgments "],["intro.html", "Chapter 1 Introduction 1.1 Who is this bookdown for? 1.2 Why this bookdown project? 1.3 Pedagogy 1.4 The Abelson Principle 1.5 Book layout 1.6 R code formatting 1.7 Exercises and data", " Chapter 1 Introduction This book provides an advanced introduction to doing statistics with R (R Core Team 2020b), equipping the reader with the programming skills necessary to do statistics cheaply, efficiently - and perhaps most importantly - in a reproducible fashion. 1.1 Who is this bookdown for? It is primarily geared toward students who have some familiarity with basic statistical concepts. In the United States, that would be advanced undergraduates and beginning graduate students. While it does cover much of the same ground as an introductory course, it covers those topics in greater detail and with an eye toward exploring those statistical concepts within R. The hope is that being a better R programmer will make you a better statistician and that being a better statistician will make you a better R programmer. 1.2 Why this bookdown project? Lots of really good resources for learning R and/or statistics exist, for example, Cetinkaya-Rundel and Hardin (2020) “Introduction to Modern Statistics” Ismay and Kim (2020) “Statistical Inference via Data Science” Phillips (2018) “YaRrr! The Pirate’s Guide to R” Wickham and Grolemund (2017) “R for Data Science” Bryan (2019) “STAT545” So, why write another one? The best way to answer that question is probably with the big idea motivating this material, specifically the intuition that statistics is, in the first place, a framework for building and evaluating models of the world. This idea guides the book’s layout and content, providing a fresh approach to statistics and statistical programming. It may be juxtaposed with a common strategy for teaching introductory statistics, which goes something like this. First, you introduce students to some descriptive statistics, beginning with properties of a single variable, including measures of its central tendency, its variability, and its shape and skew. From there, you move on to discussing various significance tests, like Student’s T. Finally, you reach the topic of modeling, covering such things as ordinary least squares and perhaps generalized linear modeling. If you had to give it a name, you might call this breezy strategy the Describe-Test-Model (DTM) paradigm of statistics pedagogy. As an alternative to DTM, this book adopts an Everything-is-a-Model (EM) approach. EM has many advantages over DTM, but perhaps the two most important are these: It is more intuitive. It starts from the idea that when we use statistics, our primary goal is to understand an empirical (or data generating) process, be it the efficacy of a medical treatment, the causes of ocean fishery collapse, or simply differences in the height of actors who auditioned for the roles of Aragorn and Gimli in the timeless cinematic classic, The Lord of the Rings. We do that by first proposing a model of the target process (this is statistical description) and then to ask if our proposed model is better at describing that process than alternatives (this is statistical inference). It emphasizes critical thinking. A fundamental weakness of the DTM approach is its emphasis on rote learning. Students are trained to be, as it were, statistical parrots, able to reliably squawk “aark! t-test!” in the correct circumstances without ever understanding that test’s meaning. By emphasizing statistical inference as a method for choosing between models, the EM approach invites the student to move beyond this simple statistical parroting, to actively think about what it is they are doing when they apply a statistical test. And, for the statistical purists out there, EM ruthlessly enforces the distinction between statistical description and statistical inference. For details about this perspective, have a look at Chapter 12 What is statistics?. To see how someone might take the EM approach and run off a cliff with it, have a look at Jonas Kristoffer Lindelov’s very insightful and very enjoyable article Common statistical tests are linear models (or: how to teach stats). Now, if I’m being honest, there are a few additional reasons to prefer this book over others. First, it’s brief. That’s because it doesn’t try to do everything. At the end of the day, there’s no substituting for the guiding hand of a thoughtful teacher. This book embraces that idea, offloading a lot of what is “unsaid” into the classroom. For instance, there’s no discussion of how to install R! Second, the book does not shy away from mathematical notation, which seems to be more in vogue these days, though it does so sparingly. Third, it doesn’t treat you like a child. As far as we are concerned, you’re an adult, so we treat you like you one. Of course, that’s not to say this book doesn’t have a sense of humor. It very much does, which brings me to the final reason you should prefer this book. The humor in it is mine. 1.3 Pedagogy To understand the pedagogy adopted here, consider by analogy the plight of an exchange student venturing abroad to learn a new language. What we might call the pure inquiry-based approach to the student’s situation would be to, well, parachute them into the heart of a foreign land, perhaps offering them a swift kick and a lackadaisical “good luck!” on their way out. Alternatively, we could adopt a pure instructor-driven approach. You know the kind, drills, repetition, and rote memorization, Monday Tuesday Wednesday Thursday Friday, always the same, until you’ve snuffed out the last spark of curiosity. With the former approach, the student will almost assuredly become hopelessly lost. With the latter, of course, they will simply check out. To avoid these unwanted outcomes, we adopt a hybrid approach to teaching statistics and statistical programming in R, starting with traditional instructor-driven factual knowledge to present basic R concepts and then moving to a more inquiry-based or question-oriented approach1 to explore statistical concepts. So, we provide the reader with some basic R scaffolding, which they can then extend and enrich through their question-directed, deep-dive into fundamental statistics. Of course, that’s not to say that the R introduction is entirely declarative, or the statistics introduction entirely interrogative. For we encourage the reader to think about R programming tools in terms of how they complement the scientific method. And, we also provide explanations of statistical concepts, too. I mean, we’re not going to ask the reader to interrogate their way from Pythagoras to R.A. Fisher. The idea is, instead, to always draw their attention to and ask them to think deeply about how one uses quantitative methods to choose between alternative statistical models of the underlying process we hope to understand. 1.4 The Abelson Principle A lot of instruction in programming seems to focus on how one must write it, without ever explaining how one should write it. This is a mistake, akin to teaching someone to speak a language but not how to communicate with it effectively. We want to avoid this, so we provide a style guide right away (Chapter 5). Obviously, such a guide cannot avoid being arbitrary (in the sense of lacking an objective “foundation”), but that doesn’t mean it can’t still be reasonable. To ensure its reasonableness, we emphasize with our guide the writing of code that promotes reproducible research, where ‘reproducibility’ refers to the ability of different individuals to obtain the same or similar results when implementing the same or similar methods. With respect to reproducible programming, perhaps the most important thing you can do is ensure that your code satisfies what we refer to as the Abelson Principle2: Programs must be written for people to read, and only incidentally for machines to execute. -Hal Abelson, The Structure and Interpretation of Computer Programs To unpack that a little, we might say that R code should be (i) clear, (ii) concise, and (iii) organized. Clear code wears its meaning on its sleeve. While code can and often does get very complicated, one should always take care to ensure that discerning its intent is as easy as possible. Concise code sticks to the main purpose of the analysis and does not include extraneous operations. Organized code has a clear order and direction. An outline is provided, and sections of the outline are clearly identified within the script. Throughout this book, we have tried, as far as possible, to satisfy this Abelson Principle. We also encourage the reader to do so as well. 1.5 Book layout At its core, the book is designed to satisfy one mighty constraint. Specifically, it aims to cover content that advanced students and instructors should - at least, hypothetically - be able to cover in a semester-length course (that’s roughly 14 weeks in the United States). Our strategy for satisfying this time-constraint is twofold. First, Part I provides a broad but shallow introduction to R. Consequently, readers are introduced to basic programming skills and given indications of where to look for more depth. For example, the book excludes any discussion of R Markdown, focusing instead on basic scripts as a tool for reproducibility. Conversely, Part II provides a deep but narrow introduction to introductory statistics. So, the text foregoes discussion of such things as ensemble modeling and dimensional reduction, opting instead to provide greater detail about probability distributions, significance tests, and multivariate models (both simple linear models and generalized linear models). This strategy also conforms to the pedagogy outlined above. 1.5.1 Chapter overviews At the beginning of each chapter, you will find a table with a chapter overview. These tables enable you to get a sense of what the chapter will cover at a glance. Here is the overview table for Chapter 6: R Basics: Goal To provide a brief overview of basic R functionality. tl;dr It’s not just a calculator. Outcomes Here, you will learn about doing arithmetic with R, creating objects with assignment, doing things with functions running code in the console, writing scripts, and using R packages. Datasets NONE Requirements NONE Further Reading An Introduction to R (R Core Team 2020a)R FAQ (Hornik 2020) As you can see, it includes these six components: Goal. A short statement regarding the general lesson to be learned. tl;dr. Reddit-speak for “too long, didn’t read.” This provides a short summary description of the actual lesson. Outcomes. A numerical list of the specific skills and concepts you will learn. Data sets. The specific data you will need to run the R code used in the chapter. We try hard to provide citations for the data and links to web pages that provide more details. Requirements. A list of the skills and concepts you need to know already in order to follow along. Further Reading. Some suggestions regarding where one can look for more information about the chapter topic. Full citations are added at the end of each chapter. Where possible, links to the references are provided. 1.6 R code formatting In this section, we just want to touch briefly on two important formatting choices for R code. First, you will on occasion see inline code that looks like this: seq(2, 200, by = 2). This code is gray shaded and has a code font. We typically use this inline code when we want to refer to a specific object or function. For longer code sequences, including multiple object and function calls, we use code chunks that look like this: 1 + 1 ## [1] 2 Note, however, that on your own computer, the code that you run will look like this: &gt; 1 + 1 [1] 2 There are two big differences here. First, on your computer, but not in this book, code will always begin with the “prompt,” i.e., the greater-than symbol &gt;. Second, in this book, but not on your computer, the results of executing some bit of code will be commented out with two pound signs ##. These two differences facilitate copying code directly from the book and onto your computer. You will notice, too, that many of the code chunks in this book are littered with comments. These begin with a single pound sign #, for example, # hey look, I&#39;m a comment in R 1 + 1 ## [1] 2 These are provided in code chunks as a source of additional guidance, though we try to provide most of the explanation for what we are doing outside of the code chunk, in the primary flow of the prose. Throughout the book, we have also chosen to follow a consistent set of conventions for referring to R code proposed by Hadley Wickham and Garrett Grolemund in their R for Data Science book (see Chapter 1.5 Running R Code). These include: Referring to functions using code font and parantheses, e.g., mean() and seq(). Referring to function arguments using code font without parantheses, e.g., na.rm. Referring to R objects (like data and classes) using code font without parantheses, e.g., penguins and raster. Referring to packages using code font without parantheses, e.g., dplyr and mgcv. And, if we need to make it clear what package a function or dataset is from, we will refer to it using the package name and the function/data separated by two colons, e.g., dplyr::mutate() and palmerpenguins::penguins. (Using colons in this way is also proper R syntax.) 1.7 Exercises and data Chapter exercises are built on a separate platform, specifically Canvas, including all necessary data. Eventually, we hope to bundle the data and exercises into an R package. Unfortunately, that won’t be happening any time soon… References "],["r-and-rstudio.html", "Chapter 2 R and RStudio 2.1 What is R? 2.2 Why R? 2.3 RStudio", " Chapter 2 R and RStudio Figure 2.1: R in the wild. 2.1 What is R? R is variously described as a programming language for statistical computing and as a programming environment (Hornik 2020). In fact, if you use R to conduct any statistical analysis that will likely end up in a scientific publication, you will want to refer to it as such – to say something like “All analyses were conducted in the R Programming Environment” or “All analyses were conducted with the R Programming Language” – and then to cite it! For example, Statistical analysis was performed in R version 4.0.3 (R Core Team 2020b). And the full citation you can now see in the References below. 2.1.1 The R Environment According to the R Core Team (2020a), referring to R as an environment “is intended to characterize it as a fully planned and coherent system, rather than an incremental accretion of very specific and inflexible tools.” Now, on its face, this is a somewhat strange claim, as the word ‘environment’ would seem to suggest a physical surrounding composed of unplanned and incremental accretions. What is more, the R Programming Environment is not immune, as the quote would suggest, to constraints imposed by its history and evolution. Nowhere is this more apparent than in the myriad syntactic inconsistencies that have proliferated over the last 25 years of R’s development (Wickham 2015). Still, the word ‘environment’ is a good one, for R really is an environment that one can enter into, so to speak, and there do lots of very fun, very interesting, and very meaningful things, like complex data manipulations, fancy statistics, and data visualization (see Chapter 3 for an example workflow!). In this sense, you can think of it as a literal terminal or console on your computer that you type commands into. You can also think of the R environment as the place where the objects you make live and breath and have their being. In this sense, it is like a digital zoo or menagerie because the environment has (or should have, anyway) a lot more order to it than, say, a natural landscape unadulterated by human action. For more on the R environment, see Chapter 9: Workspace Management. 2.1.2 The R Language R is also a functional programming language (Hornik 2020) in the sense that it has a well-defined syntax and semantics, which together define rules for combining symbols into complex strings and interpreting their meaning. This is partially what they meant, I think, when the R Foundation described R as a “coherent system.” It is a coherent set of rules that govern the writing of code and its execution. I mean, you can’t just type anything into the R console and expect to get a result. For example, 5 - &quot;blargh!&quot; #### Error in 5 - &quot;blargh!&quot;: non-numeric argument to binary operator is just gibberish and as you see, R protests. But mean(1:5) ## [1] 3 is not. This string of symbols is simply requesting the mean of the numbers 1 through 5. R understands this and thus returns the desired output. 2.2 Why R? Actually, ‘R’ is a play on ‘S’, the name of the language R is based on, which John Chambers developed at Bell Labs in 1976. ‘R’ is also a reference to its authors, Ross Ihaka and Robert Gentleman, who began working on R at the University of Auckland in New Zealand, releasing it piecemeal into the digital wilds starting in 1993 (Hornik 2020). But, maybe you want to know why you should use R. Well… 2.2.1 It’s free! R is free software under the terms of the Free Software Foundation’s GNU General Public License. 2.2.2 It’s statistics made easy Using R lets you exploit the awesome computing powers of the modern world. Just try to do maximum likelihood estimation on, say, 10,000 observations of a half-dozen variables by hand. It is NOT worth it. But it is with R! And, what is more, R provides an elegant and concise syntax for writing these complex statistical operations. # fit a generalized linear model with a Gaussian error distribution to the data glm(formula = y ~ x1 + x2 + x3 + x4 + x5, family = gaussian, data = my_ten_thousand_observations) 2.2.3 It’s pretty figures One of the most powerful features of R is its ability to produce publication-quality plots. For instance, R’s native graphics engine allows you to plot this normal distribution: 2.2.4 It’s reproducible R also facilitates reproducible research. It does this in two ways. First, it forces you to declare explicitly each step in your analysis. set.seed(12345) my_data &lt;- sample(1:1000, size = 100) mu &lt;- mean(my_data) std_dev &lt;- sd(my_data) We see here that someone has set the seed for R’s random number generator, sampled one hundred numbers between 1 and 1000, then taken the mean of that sample and its standard deviation. Everyone can now see this process and repeat it verbatim for themselves. Crucially, everyone also includes future-you, that stranger who might one day look back and wonder, “How did I do this?” The second way that R promotes reproducible research is by making R code like this shareable. In the simplest case, we use R scripts, which are text-based files containing R code that you or someone else with an R installation can run. Alternatively, we can use R Markdown, a much more flexible tool for not only writing and saving R code, but for explaining in detail what you are doing alongside the code itself. 2.2.5 It’s an active community R is also an incredibly active and growing community, with lots of rich and informative documentation, and forums where one can go to get help trouble-shooting problems. There are a lot of ways to visualize this idea, but here is one, the number of downloads of R from the online RStudio CRAN mirror (not necessary to know what that is) from 2015 to the present. 2.3 RStudio If you are going to do anything with R, RStudio is hands-down the best place to do it. RStudio is an open-source integrated development environment (or IDE) that makes programming in R simpler, more efficient, and most importantly, more reproducible. Some of its more user-friendly features are syntax highlighting (it displays code in different colors depending on what it is or does, which makes it easier for you to navigate the code that you’ve written), code completion (it will try to guess what code you are attempting to write and write it for you), and keyboard shortcuts for the more repetitive tasks. By far, though, the best feature RStudio offers is a customizable workbench or visual interface for R programming (described in the next section). 2.3.1 Pane layout When you first open RStudio, you should see three window panes: the Console, the Environment, and the Viewer. If you open an R script, a fourth Source pane will also open. The default layout of these panes is shown in Figure 2.2. Figure 2.2: RStudio Default Four Pane Layout Source. The Source pane provides basic text editing functionality, allowing you to create and edit R scripts. To open an R script in RStudio, just click the green and white plus-sign button displayed below File and select “R Script.” Note that you can also achieve this by using the RStudio keyboard shortcut Ctrl+Shift+N. Importantly, you cannot execute the code in these scripts directly, but you can save the scripts that you write as simple text files. A dead give away that you have an R script living on your computer is the .R extension, for example, my_script.R. For some directions on how to properly format your R scripts and code to make them more human-readable, see Chapter 5: R Style Guide. For more on how to use R scripts, specifically how to execute the code they contain, see Chapter 6: R Basics. Console. The Console pane, as its name suggests, provides an interface to the R console, which is where your code actually gets run. While you can type R code directly into the console, you can’t save the R code you write here into an R script like you can with the Source editor. That means you should reserve the console for non-essential tasks, meaning tasks that are not required to replicate your results. For more on the R console, see Chapter 6: R Basics. Environment. The Environment pane is sort of like a census of your digital zoo, providing a list of its denizens, i.e., the objects that you have created during your session. This pane also has the History tab, which shows the R code you have sent to the console in the order that you sent it. Viewer. The Viewer pane is a bit of a catch-all in terms of its functionality, though I suspect the primary use you will make of it is to view the graphical output of your R code, hence calling it the Viewer pane. At any rate, the four tabs most relevant for the topics discussed in this book are the Files tab, the Plots tab, the Help tab, and the Viewer tab. The Files tab works like a file explorer. You can use it to navigate through folders and directories. By default, it is set to your working directory. The Plots tab displays any figures you make with R. The Help tab is where you can go to find helpful R documentation, including function pages and vignettes. For more on how to access help documentation and other sources of R support, see Chapter 4: Looking for Help. The actual Viewer tab provides a window to visualize R Markdown (anything generated by knitr, really) and Shiny output. References "],["example-workflow.html", "Chapter 3 An Example Workflow 3.1 In fits and starts 3.2 The whole shebang", " Chapter 3 An Example Workflow Figure 3.1: An idealized workflow in R 3.1 In fits and starts To give you a feel for what all can be done with R, let’s walk through an example workflow, as shown in Fig. 3.1. This typically involves importing data, reshaping and/or subsetting it to get it into a format necessary for analysis, doing some preliminary descriptive statistics to explore general properties of the data, doing some inferential statistics to investigate trends in the data, and summarizing the results of the analysis. At various stages, visualizing the data will be extremely helpful, either to explore the data further or to help communicate the results to others. A lot of the output of this process, we will also want to save for later, perhaps to include in a publication (like a figure or model summary), but maybe also to avoid repetition of difficult and time-consuming tasks. Now, obviously, the diagram in Figure 3.1 is meant to give you a feel for what a typical workflow should look like, at least ideally. As you can see, it is very austere and organized, almost linear, with cool, pleasant colors. You might even call it inviting. Do not be fooled, however. For what you will actually encounter with your work will often look like this: Figure 3.2: The often circuitous and sometimes painful maze of statistical analysis in R. The path traversed through the maze in this figure has a disorienting, almost chaotic, feel to it.3 It suggests - correctly - that statistical programming involves lots and lots of false starts, dead-ends, and backtracking. Frankly, there’s no avoiding these frustrations, but that’s not because what you’re doing is statistical programming per se, but rather just writing to express ideas. And, like any writing exercise, you start with a blank page, add content here or there, and then, you know, revise, revise, revise, until you get something sufficiently polished that it conveys its intended meaning well. So, as I walk through this example workflow, maybe think about the idealized diagram more as a representation of your final (or final-ish4) draft (“script,” in code talk), and then the maze is just the frustrating, though ultimately rewarding, write-and-revise path to get there. 3.2 The whole shebang 3.2.1 Load data penguins &lt;- read.csv(&quot;penguins.csv&quot;) head(penguins) ## species island bill_length_mm flipper_length_mm body_mass_g sex year ## 1 Adelie Torgersen 39.1 181 3750 male 2007 ## 2 Adelie Torgersen 39.5 186 3800 female 2007 ## 3 Adelie Torgersen 40.3 195 3250 female 2007 ## 4 Adelie Torgersen NA NA NA &lt;NA&gt; 2007 ## 5 Adelie Torgersen 36.7 193 3450 female 2007 ## 6 Adelie Torgersen 39.3 190 3650 male 2007 3.2.2 Do grunt work Are observations of bill length missing for any penguins in this dataset? To answer this question, we can check for NA values. And if we really need that information, we can exclude those penguins from our analysis. any(is.na(penguins$bill_length_mm)) ## [1] TRUE penguins &lt;- subset(penguins, !is.na(bill_length_mm)) The exclamation point ! (often called “bang”) means “not,” so you can read that second line as “subset the penguins table and give me the rows that do not have NA values for bill length.” Now, before moving on to the fun stuff, we might want to ask a few preliminary questions of our data. How many penguins are on each island? counts &lt;- table(penguins$island) counts ## ## Biscoe Dream Torgersen ## 167 124 51 What does this distribution look like? barplot(counts) What is the mean bill length for each species? aggregate(bill_length_mm ~ species, FUN = mean, data = penguins) ## species bill_length_mm ## 1 Adelie 38.79139 ## 2 Chinstrap 48.83382 ## 3 Gentoo 47.50488 And the standard deviation? aggregate(bill_length_mm ~ species, FUN = sd, data = penguins) ## species bill_length_mm ## 1 Adelie 2.663405 ## 2 Chinstrap 3.339256 ## 3 Gentoo 3.081857 How is bill length distributed across species? boxplot(bill_length_mm ~ species, data = penguins, xlab = &quot;Species&quot;, ylab = &quot;Bill Length (mm)&quot;) 3.2.3 Do fun stuff penguin_model &lt;- lm(flipper_length_mm ~ bill_length_mm, data = penguins) summary(penguin_model) ## ## Call: ## lm(formula = flipper_length_mm ~ bill_length_mm, data = penguins) ## ## Residuals: ## Min 1Q Median 3Q Max ## -43.708 -7.896 0.664 8.650 21.179 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 126.6844 4.6651 27.16 &lt;2e-16 *** ## bill_length_mm 1.6901 0.1054 16.03 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.63 on 340 degrees of freedom ## Multiple R-squared: 0.4306, Adjusted R-squared: 0.4289 ## F-statistic: 257.1 on 1 and 340 DF, p-value: &lt; 2.2e-16 Estimate flipper length using penguin_model. est_flipper_length &lt;- predict(penguin_model) obs_flipper_length &lt;- penguins$flipper_length_mm obs_bill_length &lt;- penguins$bill_length_mm Plot the estimated trend against the observed values: plot(obs_flipper_length ~ obs_bill_length, pch = 19, cex = 1.3, col = adjustcolor(&quot;#949494&quot;, alpha.f = 0.4), xlab = &quot;Bill Length (mm)&quot;, ylab = &quot;Flipper Length (mm)&quot;) abline(penguin_model, col = &quot;#850000&quot;) mtext(text = &quot;Palmer Penguin Model&quot;, side = 3, line = 0.3, adj = 0, cex = 1.5) 3.2.4 Export results Save the cleaned data and the linear model.5 write.csv(penguins, &quot;penguins.csv&quot;, row.names = FALSE) save(penguin_model, file = &quot;penguin_model.Rdata&quot;) And that’s it! It should, anyway, because it’s a random walk.↩︎ Can we really speak of final drafts in this digital age?↩︎ Saving a figure in base R is a bit tricky, so we will leave that lesson for another time.↩︎ "],["looking-for-help.html", "Chapter 4 Looking for Help 4.1 The Google Search Paradox 4.2 Helpful helpers 4.3 Reproducible examples", " Chapter 4 Looking for Help Figure 4.1: Wisdom of the Ancients (xkcd 979). 4.1 The Google Search Paradox As you make your first tentative forays into the R programming environment, you will on occasion experience the jarring dislocation of an R error, a typically bright red eruption of your R console, perhaps symbolic of your code exploding before your eyes. Here is one of the more infamous errors you are likely to encounter: object of type ‘closure’ is not subsettable Nevermind what this particular error means.6 The point is that it can be terribly frustrating when you encounter it or one of its kin. Often troubleshooting these errors can be an additional source of anxiety and frustration, especially early on, as you simply lack the words required to describe your problem accurately and, thus, to formulate the question whose answer you so desperately need. I like to refer to this unhappy circumstance as the Google Search Paradox because you will inevitably find yourself staring at that cursed blinking cursor in the search bar, wondering what words to give to Google. It’s also a bit like Meno’s Paradox, or the Paradox of Inquiry. For if you could properly frame your question, it’s probably the case that you already know the answer. So, you either know and thus don’t need to ask, or need to ask, but don’t know how. Of course, the situation is not nearly so dire as this. In truth, you always know at least a little about your problem - you do have the error itself after all! - and can thus Google your way through to an answer - eventually, anyway. But life is fleeting, as they say, and time is short, so you should probably avoid the brute force approach, relying instead on searching efficiently. To help you with that (and to help you get better with that), this chapter provides a brief annotated list of where to look for answers, starting from within R itself! 4.2 Helpful helpers 4.2.1 R Typically, though not always, R code will have lots of supporting documentation. These come in two varieties. We’ll call them short-form and long-form documentation. The former is typically geared toward specific functions and object classes, with definitions of code components and examples of how to use them. Long-form documentation (also referred to as “vignettes”) goes over code usage and examples in greater detail. If you are having trouble specifying some particular component of your code and you know what that component is, you may find the short-form documentation more helpful. If you are having trouble getting through some analysis and you cannot pinpoint the exact reason for your trouble, the vignettes are probably where you should look. In general, though, you should think of these two forms of R documentation as the first stop along the way to troubleshooting your code. There are a couple of ways to access this documentation. From within R, you can use the help() and ?... functions to access short-form documentation. Examples include help(\"plot\") and ?plot. This will call up the function’s documentation page and display it in your computer’s graphical device. All R functions have a similar page, which provides a brief description of the function, the parameters that it takes and how these change the way it works. It is also worth scrolling down - at the bottom of the help page will be some examples of usage which you can run to get a feel for how the function works. help.search(...) and ??... both provide means of searching through help pages to find multiple functions with the same name (and potentially the same or similar uses). Simply replace the ellipses (three dots) with a character string and these functions will return all help pages with that string. So if you want to carry out a cluster analysis, typing ??cluster will search for any functions that use the word cluster; hopefully, including some that are relevant to cluster analysis. There are two very useful websites that host short-form R documentation. Those are rdrr.io and rdocumentation.org. If you Google an R function, links to its documentation on these websites are typically the first that you will see. For the best search results, I recommend Googling “R &lt;package name&gt; &lt;function name&gt;.” From within R, you can also access the long-form documentation using some combination of vignette(), browseVignettes(), and RShowDoc(). (Note that if you want to know what these functions do, you can also use, for example, help(\"vignettes\")). The function vignette() with no argument specified will bring up a list of all available long-form documents or vignettes, organized by package. If you want the vignettes for a particular R package, you can also type vignette(package = ...), for example, vignette(package = \"grid\") will bring up the vignettes for the grid package. browseVignettes() will open a locally hosted HTML page in your browser with links to all available R vignettes. This is actually quite helpful, and you should give it a try when you get a chance. Just browsing through these vignettes will give you a great feel for all that you can do in R. RShowDoc() is mostly for opening a single vignette (either as a PDF in your viewport or as an HTML page in your browser, depending on what is available). This is usefully paired with vignette(), which will give you the name of the vignette and package, so that you can, for example, call RShowDoc(what = \"plotExample\", package = \"grid\"). This will bring up the “plotExample” vignette from the grid package. Package authors have lots of resources for sharing their documentation now, including websites designed specifically to present both short- and long-form pages. Here is an example of the website for the colorspace package. Finally, you can access all available documentation (short- and long-form) for official R packages by navigating the Comprehensive R Archive Network (CRAN) website, here: https://cran.r-project.org/. 4.2.2 RStudio While RStudio provides loads of support to R users, here we mention some of the more important ones. RStudio How To Articles provide loads of how-to guides for working with R and RStudio. This is a very comprehensive suite of useful documentation. RStudio Cheatsheets strive to communicate short- and long-form documentation together in a single, concise poster format with lots of visual queues and simple definitions. These can be really helpful when you need a quick refresher on the use of some bit of code. RStudio Community is an online forum where individuals ask and answer questions about R and RStudio. They have a very strict code of conduct for their members that emphasizes mutual respect and inclusivity, so you will generally find the discussions here much more friendly and supportive. Use of this forum is highly recommended. RStudio Education is a very, very recent development by RStudio (it came online in 2020), and it is simply amazing as a resource for not only learning R itself, but also learning how to teach R. Please note that, with the exception of number 4, these RStudio help tools can be accessed within the RStudio IDE under the Help tab. 4.2.3 R Community The R community refers to R users who are actively communicating with and supporting other R users. As there are lots and lots of engaged R users these days, and more and more every day, the community is definitely thriving. There is also an expanding ethos within this community driven largely by RStudio and its code of conduct, so you will generally find R users to be a friendly bunch (if a little hoity-toity; plus, there’s always the bad apple). So, let’s talk about where you can engage with this community. We have already mentioned one, RStudio Community, but here we will list some more. Stack Overflow is a forum for programmers in all programming languages to ask and answer questions, much like RStudio Community. It’s just been around longer (2008 to be exact), which means its code of conduct has evolved over time to address a number of unanticipated issues. The consequence is that answers to questions will run the gamut from being respectful and clear to downright insulting. Still, it is a rich resource for addressing your R coding issues. And it has gotten a lot better. ROpenSci is an R programming community focused on promoting open and reproducible research in science. They have a forum much like RStudio Community, a blog with helpful news and overviews of the packages in their ecosystem, and a rich suite of webpages for their supported R packages, which you can explore here. R-bloggers is a clearinghouse for R related content, basically an aggregator of content from individual blogs. It is worth perusing every now and then to pick up the occasional gem of R understanding. The #rstats Twitter community is something. Use this if you use Twitter, I guess… The rstats subreddit is a helpful community of Redditors that are pretty good about answering questions you might have. Though do not go there asking them to do your homework for you! 4.2.4 Other Resources The UCLA Institute for Digital Research &amp; Education offers Statistical Consulting geared toward R. This is a tremendous resource for both R and statistics and is highly recommended. 4.3 Reproducible examples Others have likely asked the same question you want to ask, so you will not always need to go online, to a forum or what-have-you, and make a post yourself. But, in the off chance that you do find yourself confronted with a question never asked before, you need to make sure you provide R users with all the information and resources they need to help troubleshoot your code. This involves providing a “reproducible example” or reprex. There are two essential ingredients to a reprex: It needs to be reproducible. It might not seem obvious, but you need to make sure you provide everything needed to reproduce your error as is, for instance, all library() calls in your code. It needs to be minimal. In other words, do not include anything extraneous or burdensome, like a 400 MB data object. A much smaller R object should suffice. A lot has been written about how to put together a reprex, so rather than belabor the point here, it is perhaps best to direct you to Jenny Bryan’s reprex package, which will walk you through the process of submitting a help request on the various forums mentioned above. Though check out Jenny Bryan’s talk at the 2020 RStudio Conference: https://rstudio.com/resources/rstudioconf-2020/object-of-type-closure-is-not-subsettable/↩︎ "],["r-style-guide.html", "Chapter 5 R Style Guide 5.1 Abelson again 5.2 Be verbose! 5.3 Don’t Repeat Yourself (DRY) 5.4 Assignment first 5.5 The Cratylus Rule 5.6 Empty nests! 5.7 Be open 5.8 Be organized", " Chapter 5 R Style Guide Figure 5.1: O.P.C. (Abstruse Goose 432) 5.1 Abelson again When writing code, you should always have an eye to ensuring that it is both clear and intelligible for anyone who might come along and read it. This will ensure that your code is reproducible, which is especially important if what you are doing with R is scientific analysis. It is also just of practical value, for you will most assuredly want to reuse your code at some point in the future, or apply it to a different data set, but if you can’t make heads or tails of it, well… The following styling rules-of-thumb are inspired by the Tidyverse style guide, with a focus on those that are more relevant to beginning R coders. These rules we have tried to follow throughout this book. 5.2 Be verbose! One way to make your code clearer is to make it more verbose. Obviously, this isn’t a recommendation to include long-winded, self-indulgent soliloquies in your code. Rather, the suggestion is that you not shy away from being explicit, even if - horror of horrors! - it takes you an extra second or two to do. In other words, don’t leave it up to the reader to guess what you’re doing. Verbosity in this sense can be applied to three aspects of R code: i) object names, ii) function parameters (or arguments), and iii) coding comments. 5.2.1 Object names An old-school coding norm encouraged programmers to write highly compact code with loads of abbreviations. In general, however, you should avoid this, at least when it’s reasonable to do so. # Good mean_height &lt;- mean(height) # Bad mh &lt;- mean(height) # But, mean_height_of_actors_who_auditioned_for_aragorn &lt;- mean(height) # is overkill If the abbreviation is something obvious, though, like “USA” or “IHOP,” you should feel free to use it. 5.2.2 Function parameters When you call a function, you typically supply it with i) a data object, which the function is going to do something with, and then ii) a list of arguments, which specify how exactly the function will work with the data. You can avoid specifying the argument name for the data object, but you should strive to use the names of any arguments you override. # Good bob &lt;- mean(1:5, na.rm = TRUE) # Bad bob &lt;- mean(1:5, TRUE) 5.2.3 Code commenting Looks like some people get really worked up about this one, but just keep this in mind. Anyone reading your code should ideally be able to understand what it is doing without comments, but this frankly is not always possible (for example, for students who are first learning R!). This means you should typically keep comments to a minimum and only use them when you think it would help someone to understand not just what you are doing, but why you are doing it. 5.3 Don’t Repeat Yourself (DRY) Also known as the DRY Principle. If you find yourself copying the same code multiple times - say, three or more times a session, this is a good indication that you should write a function instead. 5.4 Assignment first Technically, R allows you to use a right-facing arrow, -&gt;, for assignment. You can also use the equal sign, =. However, even though these are allowed by R, they make your code harder to read and - at least in the latter case - ambiguous. So, you should always use the left-facing arrow, &lt;-, for assignment # Good bob &lt;- 5.137 # Bad 5.137 -&gt; bob # Ambiguous bob = 5.137 5.5 The Cratylus Rule This rule requires that a name reflect the nature of the thing named. Because objects are things and functions do things, the Cratylus Rule suggests that you should use nouns as names for R objects and verbs as names for R functions. numbers &lt;- 1:10 add_one &lt;- function(x) x + 1 5.6 Empty nests! Nesting in R is the act of calling one function inside the call to another function, like rnorm(sample(seq(1, 1000, 2)+3)). This is OK for shallow nests, meaning a function call in a function call, at least when used sparingly, but you should avoid deep nests, or a function call in a function call in a function call in…, you get the idea. In general, deep nests make your code really, really hard to read, so instead, you should assign the results of the inner functions to intermediate objects and then use those objects in the outer functions. # Bad sort(rnorm(100, mean = mean(sample(seq(1, 1000, 2), 50)))) # Good samples &lt;- sample(seq(1, 1000, 2), 50) randos &lt;- rnorm(100, mean = mean(samples)) result &lt;- sort(randos) 5.7 Be open In general, lots of white space makes it easier to read and comprehend just about any string of text, whether in books, articles, or R scripts! 5.7.1 Spacing Use lots of spaces in your code, just as you would with regular texts. That means spaces after commas, spaces around the assignment operator &lt;-, and spaces around the equal sign = in your function call. # Good bob &lt;- mean(1:5, na.rm = TRUE) # Bad bob&lt;-mean(1:5,na.rm=TRUE) 5.7.2 Line Length Think of your R script as having a giant cliff somewhere in the middle, right around 80 characters. And your job is to never go full Wiley E. Coyote with your code! Instead, return and start a new line. # Good bob &lt;- glm(y ~ x, family = gaussian, data = my_ten_thousand_observations) # Bad bob &lt;- glm(y ~ x, family = gaussian, data = my_ten_thousand_observations) 5.8 Be organized You should use commenting to give your script structure that makes it easier to navigate and to understand its intent. Intuitively, providing structure to your R script is a lot like providing structure to a term paper or a thesis. Title. You will want to include a title that indicates the aim or goal of the script, the date you wrote the script, the author(s), and where necessary, any additional notes about the intent of the script or its status. Sections. If the script is sufficiently long or complex, you will also want to carve it into named sections using section headers. Outline. If you have a lot of those sections, you might also consider adding an outline section at the beginning. Preamble. Very importantly, make sure to include an R “preamble” section where you attach all the R packages you are using, define any global options you might want to recycle throughout the script, and then source any helper functions you might want to use. # Aim: What should the script achieve # Date: 2020-01-13 # Author(s): Blake, Thor, Spiderman # Note(s): # 1. Make sure to pick up more toothpaste at the store. # OUTLINE ----------------------------------------------- # 1. R PREAMBLE # 2. IMPORT DATA # 3. EXPLORE DATA # 4. ... # 1 R PREAMBLE ------------------------------------------ # attach packages library(dplyr) library(sf) # define global options proj_crs &lt;- st_crs(26912) # source functions source(&quot;plot_helpers.R&quot;) # 2 IMPORT DATA ----------------------------------------- nc &lt;- st_read(system.file(&quot;shape/nc.shp&quot;, package = &quot;sf&quot;)) # 3 EXPLORE DATA ---------------------------------------- "],["r-basics.html", "Chapter 6 R Basics 6.1 Overview 6.2 A Glorified Calculator? 6.3 Objects and Functions 6.4 Vectorized Functions 6.5 Console and Scripts 6.6 Packages in the R Library", " Chapter 6 R Basics 6.1 Overview Goal To provide a brief overview of basic R functionality. tl;dr It’s not just a calculator. Outcomes Here, you will learn about doing arithmetic with R, creating objects with assignment, doing things with functions running code in the console, writing scripts, and using R packages. Datasets NONE Requirements NONE Further Reading An Introduction to R (R Core Team 2020a)R FAQ (Hornik 2020) 6.2 A Glorified Calculator? R has functionality for basic arithmetic operations, including + addition, - subtraction, * multiplication, / division, and ^ exponentiation. 3+2 ## [1] 5 3-2 ## [1] 1 3*2 ## [1] 6 3/2 ## [1] 1.5 3^2 ## [1] 9 6.3 Objects and Functions In R, you can make things and you can do things. The things that you make are called objects and the things that you do things with are called functions. The most common kind of R object is a vector. You can learn more about the different types of vectors in Chapter 6 Vector Types. Other kinds of objects include formula, raster, grob, hist, and density. What about functions? These are actually a special class of object that take other objects as input and typically (though not always) return other objects as output. They are thus “functions” in the sense of input-output devices. Any complex statistical operation you want to conduct in R will almost certainly involve the use of one or more functions. 6.3.1 Creating objects with assignment How do you make an object in R? Well, you just… bob &lt;- 5.137 It’s that simple! Or, maybe not. Let’s take a moment to unpack this black magic. First, we note that it is made-up of three things: a name, in this case, bob; an arrow, &lt;-, the essential ingredient in this incantation; and an object, specifically the number 5.137, which is being created. The statement adds an object (5.137) to the R environment and then assigns that object to the name bob. This is why it is sometimes referred to as an assignment statement (R Core Team 2020a). It is not just creating an object, but assigning it to a name. R has a few syntactic requirements for object names. They can only contain letters, numbers, underscores _, and periods . (or dots). And they cannot start with numbers. # Good winter_solder &lt;- &quot;Buckey&quot; object4 &lt;- 23.2 # Bad winter soldier &lt;- &quot;Buckey&quot; # spaces not allowed 4object &lt;- 23.2 # cannot start with a number R is case sensitive! So, R will not treat My_naME and my_name the same. But, why assign a name at all? Well, if we just typed 5.137 the resulting object would live a fleeting life, shorter than a fruit fly’s, being quickly created and just as quickly destroyed. But, when we give an object a name, we also give it some permanence, and can literally call it back whenever we like. We just say, “bob, come here!” but in the language of R: print(bob) ## [1] 5.137 or even just bob ## [1] 5.137 And then R summons bob for us and tells us who bob is. bob is 5.137. Obviously! Now, you may think, “I could just create 5.137 any time I wanted, let it die, and just create it again. It’s not that hard to type five characters, after all.” If you want to flirt with anarchy in this way, by all means, but let me offer two good reasons why you shouldn’t. First, it is certainly true that one number is not hard to type, but it is rare that you will need just one. Suppose you had an object consisting of ten thousand numbers, would you care to type that each time you needed it? For that matter, it would be nigh impossible to ensure you were typing the same numbers each time. Plus, when you make an object with a name, R has your back. If you type 6.137 instead of 5.137, for example, R will not protest, but if you type boo instead of bob, R will say, “nope.” 6.137 ## [1] 6.137 boo #### Error: object &#39;boo&#39; not found So, giving objects names in R is a good way to avoid errors. 6.3.2 Doing things with functions To use a function, we call it just as we would any other object, by typing its name. Unlike simple objects, though, we must also take care to append closed parentheses () to the end of the function name. Within those parentheses, we can go on to supply arguments that control how the function behaves. function_name(arg1 = value1, arg2 = value2, ...) # for example seq(1, 5, length.out = 100) If you cast your mind back to the algebra you learned in high school, this syntax should be familiar to you. Consider this algebraic expression: \\[ f(x, y) = 2x + 3y \\] It has these syntactic properties: The name of this function is \\(f\\) (just as the name of the function above is seq). Its arguments (or parameters) include \\(x\\) and \\(y\\). These are surrounded by parentheses (). And, the object the function returns is the result of summing \\(2*x\\) and \\(3*y\\). So, if you supply this function with the values 4 and 2 (as in, \\(f(x=4, y=2)\\)), it will return 14 as a result. R functions work in precisely the same way. In fact, we can demonstrate this now: f &lt;- function(x, y) 2*x + 3*y f(x=4, y=2) ## [1] 14 Notice that just as we did with regular object assignment above, we have created a function here and assigned it to a name, in this case, f. This shoud clue you into the fact that functions are objects, too, just a special sort of object that you can also do things with. 6.4 Vectorized Functions Not all functions in R are vectorized, but many are, and they provide an invaluable tool for statistical programming. What is a vectorized function? In a nutshell, it’s a function \\(f()\\) that takes a vector c(x1, x2, x3, ..., xn) as input and returns the vector c(f(x1), f(x2), f(x3), ..., f(xn)) as output. Meaning, in other words, its an action that gets applied separately to each element of a set of values. A consequence, or requirement perhaps, is that the input and output vectors have the same length (or number of elements). To make this more concrete, consider this simple function add_one(). add_one &lt;- function(x) x + 1 a_vector &lt;- c(4, 9, 16, 25, 36) add_one(a_vector) ## [1] 5 10 17 26 37 This function takes an input vector and adds one to each element in that vector. The result is an output vector of the same length, where each element has a value one greater than its corresponding element in the input vector. When it comes to these vectorized functions, R on occasion exhibits some odd behavior. For instance, operations are applied pairwise when two vectors are applied. c(1, 2, 3) + c(4, 5, 6) ## [1] 5 7 9 Here, 1 is added to 4, 2 is added to 5, and 3 is added to 6. That seems simple enough. However, when the vectors have different lengths, then R chooses to reuse numbers from the shorter length vector, starting with the first. This is known as recycling. For example: c(1, 2) + c(3, 4, 5, 6) ## [1] 4 6 6 8 Here, 1 is added to 3, 2 is added to 4, then (recycling) 1 is added to 5, and 2 is added to 6. While this is not always ideal behavior, it does at least provide a standardized or rule-based means of ensuring that everything in the longer vector gets subjected to the vectorized function. 6.5 Console and Scripts In this section, we’ll go over some basic considerations of where to write your R code and where to run it. 6.5.1 R Console Perhaps this is obvious, but you can write R code basically anywhere - on a napkin at a restaurant, for instance, on your hand in a pinch, or even in a fever dream - but if you want to get your R code to actually run, you will have to send it to the R console, so it can be interpreted. In this sense, at least, the R console is like R’s central nervous system. Signals (your code) get sent to the console to get interpreted and generate some behavioral output (like a plot or a linear model). Here is what typing R code in the actual R console looks like: Please note that in this book, the greater-than symbol &gt; preceding R code is suppressed, and that the result is preceded by ##. 6.5.2 R Scripts One important downside of writing R code directly into the console is that it is more like writing R in a dream than on a restaurant napkin. When you write code into it, you cannot get it back once you “wake up” from your R session.7 This means that working in the console subjects the reproducibility of your analysis to the sometimes (often?) unreliable testimony of your own memory - like trying to remember what happened in your dream. To overcome this limitation of the console, the authors of R have also provided a specially designed text file, called an R “script,” that you can write R code into and save to disc. A dead giveaway that you have one on your computer is the .R file extension. Note, however, that even with R scripts, you cannot just open one in a text editor and expect the code it contains to run. You would be just as well off wadding up your napkin of code and hurling it defiantly at your monitor. No, to get your code to run, wherever it resides, you must always pass it to the console to get interpreted. There are a number of ways to do this, the most basic being these: Copy and paste the code from your script into the console. This strategy, of course, makes an R script only slightly more advantageous than a napkin… To run a single line of code, place the cursor on that line and hit CTRL+Enter on PC or CMD+Enter on Mac. To run multiple lines of code, highlight those lines and hit CTRL+Enter (CMD+Enter). 6.6 Packages in the R Library R is a highly extensible programming language. Being extensible is just a fancy way of saying that individuals can write R code (more often than not, this involves writing functions) that others can later incorporate into their own workflow. These functions can be shared as simple scripts, but they can also be bundled into packages, which you can think of as being sort of like an R “app.” The basic motivation for a package is to save you from having to recreate the wheel every time you open R. That is, it saves you from having to type the same code over and over again. It’s also a powerful tool for reproducibility, as it ensures that the exact same code is run each time. To install a package, you use the install.packages() function. install.packages(&quot;dplyr&quot;) This function simply adds the package to your R library, which is more or less just a folder on your computer. To actually use the functions provided by an R package, you have to “check out” the package from the library. The way to do this in R is with the library() function. library(dplyr) Once you have done this, the functions provided by the package are now available to use. Some packages that I use in virtually all of my analyses include the following: dplyr A grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges. LINK ggplot2 A system for declaratively creating graphics, based on The Grammar of Graphics. LINK here Enables easy file referencing in project-oriented workflows. LINK sf A package that provides simple feature access for R. LINK References "],["statistical-graphics.html", "Chapter 7 Statistical Graphics 7.1 Overview 7.2 Plot anatomy 7.3 The plot() Function 7.4 Layering 7.5 Annotation 7.6 Graphical parameters 7.7 Saving figures", " Chapter 7 Statistical Graphics 7.1 Overview Goal To introduce students to the programming fundamentals of data visualization using the base R plotting system. tl;dr It’s got layers to it, like tiramisu. Outcomes Here, you will learn about the anatomy of a base R plot the plot() function, layering, annotation, graphical parameters (including font, color, and size), multi-plot layouts, and saving figures (with graphical devices). Datasets NONE Requirements Chapter 6: R Basics Further Reading An Introduction to R (R Core Team 2020a)R Graphics (2nd Ed) (Murrell 2018)R Graphics Cookbook (2nd Ed) (Chang 2019) In statistics, graphics provide visual representations of data, but why might we want to visualize data? To answer this question, we might consider a common distinction between three modes of data visualization: exploration, analysis, and presentation. Visual exploration is part and parcel of what John Tukey (1977) referred to as “exploratory data analysis” (cf Peng 2016; Tufte 2006). With it, we can (i) investigate the distribution of observations around some measure of central tendency (like the mean or median) or evaluate relationships between variables; (ii) detect problems with our data, like outliers, missing values, or other anomalies; and (iii) generate questions we may not have considered otherwise. Visual analysis, as its name suggests, is largely concerned with the statistical analyses we are conducting to answer our primary research questions. It involves such things as direct hypothesis testing, as well as evaluation of the results of statistical analyses, usually to see if the results are actually meaningful, even sometimes finding patterns that may have been missed or over-interpreted. Visual presentation is largely aimed at reporting findings to others, whether about the data itself or the results of analyses conducted with the data. Of course, the intended audience is often other scientists and researchers, but it does not have to be. Informing the public about your research is also important, and having nice graphics is a really good way of doing that. Here we are focusing on the basics of visual exploration using R’s native graphics tools, though much of what you learn here will apply more generally to visual presentation too. Highly recommend that you have a look at the R Graph Gallery, which provides code and examples for lots of different plot types, along with helpful explanations of those plot types, specifically what they are and when to use them. 7.2 Plot anatomy Producing statistical graphics in R is a lot like adding layers to a canvas. To setup a canvas and to add some default layering, we use the plot() function. This is a programming workhorse in R, used routinely and repeatedly during R sessions. Before diving into its use, though, let’s first step back to, as it were, dissect a base R plot, getting a feel for its general structure or anatomy (Fig. 7.1). In effect, this means getting a feel for the hidden layout of a plot canvas. Hopefully, this will provide you a better sense of what you are doing when, for example, you feed your plot this parameter xlim = c(0, 1). Figure 7.1: Base R plot anatomy 7.2.1 Region The plot region is the area in which geometries (like points, lines, and polygons) provide visual representations of data. Particular locations within the plot region are specified using a two-dimensional coordinate grid, the coordinates being denoted by convention as ‘x’ and ‘y’. Around the plot region, R defaults to including a plot box (represented by the light gray square in Fig. 7.1). 7.2.2 Sides The plot region is rectangular, so, naturally, it has four sides. R uses a number to refer to each side. 1 = bottom 2 = left 3 = top 4 = right Knowing how to refer to sides will allow you to control the position of other plot elements, like axes, for example. 7.2.3 Axes The scope of the plot region is defined by the x and y axes (represented by the thick orange lines), which specify the upper and lower limits of the observations to include in the plot. In Fig. 7.1, the limits are (0, 1) for both x and y. You may notice that the axes do not meet at the origin (0, 0). This is because R by default includes some padding above and below the specified limits. The most important elements of plot axes are breaks, tick marks, and tick labels. Tick marks provide a visual reference for how observations are arrayed within the plot region and are represented by short dashes emanating from each axis line. Breaks are specific values within the limits of an axis at which tick marks are displayed. By default, the breaks include the limits themselves. Ideally, break values are used as tick labels, though if you really wanted to confuse someone, including yourself, you can give them other labels as well. 7.2.4 Titles Every R plot includes four titles, the main title, the subtitle, and a title for each axis. One somewhat strange design choice on the part of the R Core Team was to place the subtitle below the x-axis title. It appears they meant the ‘sub’ in ‘subtitle’ quite literally… 7.2.5 Margins One of the more complicated features of the base R anatomy is margins. For every plot, there are two sets of these: the inner (or figure) margins and the outer margins. The inner margin (represented by the dark red box) is the area immediately surrounding the plot region, which typically involves plot titles and axis labels. The outer margin (represented by the dark blue box) is an area of additional space around the inner margin. Fiddling with the outer margin is not particularly useful in most contexts, unless you want to have multiple plot regions in one figure (discussed below in the Plot Layout section). The area of the margins is defined by “Lines,” named starting with 0. By default, the inner margin is four lines in width (Line 0 to Line 3) and the outer margin is three lines in width. These lines may be used to position other plot elements, including, more often than not, plot titles. Note that R does not include the outer margin by default. It must be added explicitly using Graphical Parameters (see below). 7.2.6 Legend A legend or key provides a list of additional variables represented by symbols or colors in the plot region, along with the symbols or colors used. By default, R includes the legend within the plot region, but it is possible to move it to the inner or outer margin. 7.3 The plot() Function At its core, the plot() function is simply a tool for mapping data onto a grid (the plot region in Fig. 7.1). Consider, for example, these values of x and y. x &lt;- c(0.0, 0.2, 0.3, 0.5, 0.6, 0.8) y &lt;- c(0.9, 0.8, 0.6, 0.5, 0.3, 0.1) When you supply plot() with these values, it maps them to a grid like so. Figure 7.2: Mapping data onto a grid. There are two ways to supply the plot() function with these x and y values: (i) as separate vectors or (ii) as a combined formula. As separate vectors plot(x, y) As a combined formula plot(y ~ x) Notice the tilde, ~. This may be read as “… is a function of …”, in this case “y is a function of x.” I go back and forth about which style is more preferable, or I should say, more reproducible. The formula notation is better for conveying that you are plotting a relationship. However, providing the x and y vectors separately to plot() is more suggestive of what the function is actually doing, which is to map coordinates onto a grid. So, for now, I think I would recommend that you simply choose the style that feels more comfortable to you. RStudio displays the result of calling plot() in the Viewer pane, by default the bottom right window pane. The plot() function is a tad more complicated than this simple introduction would suggest, for it will produce different types of plot depending on what kind of object x is. In the technical idiom of R, this makes plot() a generic function. 7.3.1 Plot type By default, plot() provides for nine different types of plot. These are specified using the argument type. Options include all of the following: \"p\" (points), \"l\" (lines), \"b\" (both points and lines), \"c\" (lines with missing points), \"o\" (points plotted over lines), \"s\" (stair steps), \"S\" (stair steps inverted), \"h\" (histogram-like vertical lines), \"n\" (nothing). So, if you want to plot points, for instance, you would type plot(y ~ x, type = &quot;p&quot;) And just so you can see the result, here are examples of each: Figure 7.3: Default plot types. 7.3.2 Plot limits One of the most important features of a plot is its limits. By default, plot() uses the range of the x and y vectors. In this case, the range of x is [0, 0.8] and the range of y is [0.1, 0.9]. You will perhaps have noticed, however, that the limits in Figures 7.2 and 7.3 are [0, 1]. That is because we supplied plot() with these values using the arguments xlim and ylim. plot(y ~ x, xlim = c(0, 1), ylim = c(0, 1), xlab = &quot;X&quot;, ylab = &quot;Y&quot;) Individuals with a chaotic-evil alignment will feel tempted to abuse plot limits to obscure or exaggerate features of their data. You see, for example, in our toy data that the points have a certain trend starting in the upper left corner of the plot and falling to the lower right. What do you think would happen to the look of that trend, though, if we were to specify new limits for y, say [0, 100]? 7.4 Layering Whenever you use plot(), it establishes a new “canvas” and provides some default plot elements (specifically x and y axis titles, a box around the plot region, and tick marks and labels). These can all be “turned off,” so that plot() simply establishes an empty canvas. plot(y ~ x, type = &quot;n&quot;, xaxt = &quot;n&quot;, # remove the x-axis yaxt = &quot;n&quot;, # remove the y-axis xlab = &quot;&quot;, # remove x-axis title ylab = &quot;&quot;, # remove y-axis title frame.plot = FALSE) # remove the box around the plot region Figure 7.4: ‘A blizzard’ by M. Duchamp Now, let’s add the defaults back incrementally. Figure 7.5: Layering. The plot title explains what function is being used to add each layer. This is what we mean by “layering.” As you can see, plot() not only establishes an empty canvas, but adds some default layers. And to those defaults, we can add even more! In fact, here is a list of really, really useful layering functions. Function Description abline() Adds one or more straight lines through the current plot. axis() Adds an axis to the current plot, allowing the specification of the side, position, labels, and other options. box() Draws a box around the current plot in the given color and linetype. curve() Draws a curve corresponding to a function over the interval [from, to]. grid() Adds rectangular grid to an existing plot. lines() A generic function taking coordinates given in various ways and joining the corresponding points with line segments. mtext() Writes text in one of the four margins of the current figure region or one of the outer margins of the device region. points() A generic function to draw a sequence of points at the specified coordinates. polygon() Draws a polygon whose vertices are given by x and y. rect() Draws a rectangle (or sequence of rectangles) with the given coordinates, fill and border colors. segments() Draw line segments between pairs of points. text() Draws the strings given in the vector labels at the coordinates given by x and y. title() Add labels to a plot. Figure 7.5 shows how some of these functions work. Here is the code used to generate that plot. plot(y ~ x, type = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;, xlab = i, ylab = &quot;&quot;, col.lab = &quot;white&quot;, frame.plot = FALSE, xlim = c(0, 1), ylim = c(0, 1)) # add axes axis(side = 1) # x-axis to bottom axis(side = 2) # y-axis to left # add box around plot region box() # add axis labels title(xlab = &quot;X&quot;, ylab = &quot;Y&quot;) # add points points(y ~ x) 7.5 Annotation Generally speaking, annotation refers to the addition of natural language elements (i.e., characters, words, and numerals) to a plot. These include plot titles (the main title, the subtitle, and the axis titles), as well as the legend title, axes labels (i.e., the tick labels, usually numerals), and any other text comments, either within the plot region or in the margins. Much of this may be specified within the plot() function itself. plot(y ~ x, xlab = &quot;X-axis Label&quot;, ylab = &quot;Y-axis Label&quot;, main = &quot;Main Plot Title&quot;, sub = &quot;Literally, below the plot title&quot;) Specifying these title annotations within plot() should be sufficient for simple plots, but for more fine grained control, you will want to use the title() function. plot(y ~ x, xlab = &quot;X-axis Label&quot;, ylab = &quot;Y-axis Label&quot;) title(main = &quot;Main Plot Title&quot;, col.main = &quot;red3&quot;, # color of main title line = 0.3, # inner margin line location adj = 0) # text alignment left title(sub = &quot;Literally, below the plot title&quot;, col.sub = &quot;orange3&quot;) Sometimes it is useful to label points or other geometries in the plot region. For this, R provides the text() function. As with the geometries themselves, the key here is to provide coordinates for where to locate the text. In this case, we use the point coordinates, since we are labeling them. plot(y ~ x, xlab = &quot;X&quot;, ylab = &quot;Y&quot;, xlim = c(0, 1), ylim = c(0, 1)) # create point labels having the form &quot;(x, y)&quot; point_labels &lt;- paste0(&quot;(&quot;, x, &quot;, &quot;, y, &quot;)&quot;) text(y ~ x, pos = 4, # place text on the right side of the coordinate location offset = 0.4, # add this much space between coordinate and text labels = point_labels, cex = 0.8) You can also add text to the inner or outer margins with mtext(). Since you are plotting outside the plot region, you specify the location of text in the margin using the side, line, and adjustment (or alignment), rather than coordinates. plot(y ~ x, xlab = &quot;X&quot;, ylab = &quot;Y&quot;, xlim = c(0, 1), ylim = c(0, 1)) mtext(text = &quot;(side = 3, line = 1, adj = 1)&quot;, side = 3, line = 1, col = &quot;red3&quot;, adj = 1) mtext(text = &quot;(side = 1, line = 4, adj = 0)&quot;, side = 1, line = 4, col = &quot;darkblue&quot;, adj = 0) 7.6 Graphical parameters Graphical parameters control aesthetic aspects of a plot, for example, color and size. R provides two ways to set these parameters. If you want to make changes to a single plot, you can supply graphical parameters to the plot() call directly. For instance, plot(y ~ x, pch = 19) supplies the plot() function with the graphical parameter pch = 19, which specifies the type of point symbol to use (in this case a filled circle). Note that the layering functions mentioned above will also take graphical parameters in this way. You can also define graphical parameters globally, which means they will affect all plots the same way (well, more or less the same way). You do this by calling the par() function and supplying graphical parameters to it. For example, par(pch = 19) sets the point symbol to the filled circle for all plots. Note, however, that par() does not actually plot anything itself. It merely changes the properties of the plots that come after, which you will see only when you explicitly call the plot() function (or one of its ilk). Sometimes you will want to set graphical parameters for several plots then revert to the original parameters for subsequent plotting. To do this, you simply assign the parameters to an object, like so: original_parameters &lt;- par() # new parameter specifications par(pch = 19) ### &lt;do some plotting here&gt; # revert to original parameters par(original_parameters) Now, let’s go over just a few of the many, many graphical parameters and how they affect your plot aesthetics. For an exhaustive list of graphical parameters and examples of their effect, see Porra (2017) “Graphical parameters of R {graphics} package” at RStudio Pubs. 7.6.1 Region Whenever working with base R graphics, one graphical parameter I turn to compulsively is pty. This controls the type of plot region, of which there are two, a square plot region (with value s) and a maximal plot region (with value m, this is the default). In almost all cases, I find the square plot region to be, well, more aesthetically preferable. Does it have any relevance at all to reproducible code? Doubtful, but come on, nobody’s perfect! Plus, now I can make the remaining plots in this chapter perfectly square, as I wanted to do all along! An example: par(pty = &quot;s&quot;) plot(y ~ x, type = &quot;p&quot;, xlab = &quot;X&quot;, ylab = &quot;Y&quot;, xlim = c(0, 1), ylim = c(0, 1)) pty is actually one of those graphical parameters that can be set only with par(). 7.6.2 Geometry R allows you to specify graphical parameters for points and lines (and by extension, polygons), for example, the type of symbol used to display the geometry. For points, this is controlled by pch. For lines, by lty. pch can take any value from 0 to 25, lty any value from 0 to 6. lty can also be specified with the words \"blank\", \"solid\", \"dashed\", \"dotted\", \"dotdash\", \"longdash\", and \"twodash\". Here is what these look like. Notice that point symbols 0-14 are unfilled, 15-20 are filled and a single color, and 21-25 are filled and different colors, one for the line and one for the fill. Here is an example of changing the point symbol using our x and y vectors from above: par(pty = &quot;s&quot;) plot(y ~ x, type = &quot;p&quot;, # &#39;p&#39; for &quot;point&quot; pch = 17, # set point type here xlab = &quot;X&quot;, ylab = &quot;Y&quot;, main = &quot;Strange Points&quot;) And here is an example of changing the line type: par(pty = &quot;s&quot;) plot(y ~ x, type = &quot;l&quot;, # &#39;l&#39; for &quot;line&quot; lty = 4, # set line type here xlab = &quot;X&quot;, ylab = &quot;Y&quot;, main = &quot;Strange Line&quot;) 7.6.3 Text There are several ways to modify text output in a plot. Here we will focus on font type (meaning, normal, bold, or italic) and justification (or alignment, for example, centered text). These are controlled by font and adj, respectively. font can take any value from 1 to 4, adj any continuous value from 0 for left aligned to 1 for right aligned, with 0.5 being the value for centered text. Note that R provides multiple font parameters that allow you to control the font of specific plot elements. Those include: Parameter Description font Font of text and symbols in the plot region. font.axis Font of axis tick labels. font.lab Font of axis labels. font.main Font of main title. font.sub Font of subtitle. Here is an example: par(pty = &quot;s&quot;) plot(y ~ x, type = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;, xlim = c(0, 1), ylim = c(0, 1)) axis(side = 1, font.axis = 3) # who comes up with these names? axis(side = 2, font.axis = 2) points(y ~ x, pch = 19) title(main = &quot;Strange Fonts&quot;, line = 0.3, adj = 0, font.main = 4) title(xlab = &quot;X&quot;, ylab = &quot;Y&quot;, font.lab = 2) title(sub = &quot;Italics are for emphasis.&quot;, font.sub = 3) 7.6.4 Color The graphical parameters controlling color all begin - somewhat intuitively - with col. Each allows you to modify the color of a specific plot element. They include: Parameter Description col Color of text and symbols in the plot region. col.axis Color of axis tick labels. col.lab Color of axis labels. col.main Color of main title. col.sub Color of subtitle. Now, we just need a way of telling those parameters what colors we want to use. For this, R offers a number of tools, the two most commonly used being the name of the color and the number R has assigned to it. For a complete list of R color names, you can use the colors() function. all_R_colors &lt;- colors() all_R_colors[1:3] ## [1] &quot;white&quot; &quot;aliceblue&quot; &quot;antiquewhite&quot; Combining these color specifications with the listed graphical parameters allows us to create this monstrosity: par(pty = &quot;s&quot;) plot(y ~ x, type = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;, xlim = c(0, 1), ylim = c(0, 1)) axis(side = 1, col.axis = &quot;blue4&quot;) # who comes up with these names? axis(side = 2, col.axis = &quot;blue4&quot;) points(y ~ x, pch = 19, col = &quot;darkgoldenrod&quot;) title(main = &quot;Strange Colors&quot;, line = 0.3, adj = 0, col.main = &quot;aquamarine4&quot;) title(xlab = &quot;X&quot;, ylab = &quot;Y&quot;, col.lab = &quot;darkorchid&quot;) title(sub = &quot;Can&#39;t unsee this plot.&quot;, col.sub = &quot;deeppink4&quot;) 7.6.5 Size The graphical parameters controlling size all begin - somewhat confusingly - with cex. Each allows you to modify the size of a specific plot element. They include: Parameter Description cex Size of text and symbols in the plot region. cex.axis Size of axis tick labels. cex.lab Size of axis labels. cex.main Size of main title. cex.sub Size of subtitle. Here is an example: par(pty = &quot;s&quot;) plot(y ~ x, type = &quot;n&quot;, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;, xlim = c(0, 1), ylim = c(0, 1)) axis(side = 1, cex.axis = 1.3) axis(side = 2, cex.axis = 1.3) points(y ~ x, pch = 19, cex = 3) title(main = &quot;Strange Sizes&quot;, line = 0.3, adj = 0, cex.main = 3.5) title(xlab = &quot;X&quot;, ylab = &quot;Y&quot;, cex.lab = 2) title(sub = &quot;This is the literal sub-title. Also, the fine print.&quot;, cex.sub = 0.5) Note that the graphical parameter lwd works for lines and segments the same as cex does for all the rest. par(pty = &quot;s&quot;) plot(y ~ x, type = &quot;l&quot;, lwd = 5, xlab = &quot;X&quot;, ylab = &quot;Y&quot;, xlim = c(0, 1), ylim = c(0, 1)) That all seems easy enough. But, what exactly do the numbers mean? This is not obvious, for they are not tied to a specific unit of measure (like centimeters or inches). What are they tied to? Well, a graphical device! We’ll go over what that means exactly in a minute, but for now just keep in mind that the same number can look different depending on which device you use. 7.6.6 Margin The thing to keep in mind about plot margins is that you should mess with them in maybe one circumstance and otherwise just leave them alone. What is that circumstance? Multi-plot layouts! But, that’s for the next section. Let’s just get a feel for how to manipulate the margins. Recall that there are actually two sets of margins, the inner and outer margins (Fig. 7.1). The graphical parameters that control these are mar for the inner margins and oma for the outer margins. To specify these, you need to pass each a vector having precisely four numerical values. Don’t worry, you’ll learn what a vector is in the next chapter. The important thing for now is that the order of the values matters. Why? Well, because the first value you pass specifies the width of the bottom margin (that’s side 1 if you recall). The second value specifies the width of the left margin, the third the width of the top margin, and the fourth the width of the right margin. So, your vector of margin widths should look like this: par(mar = c(bottom, left, top, right)) Note: this is not proper R syntax as bottom, left, top, and right are undefined. It is merely meant to illustrate the idea. A real example would look like this: par(mar = c(5, 4, 4, 2)) In fact, these are the default settings (well, more or less). Now, here’s what changing the margins looks like: Figure 7.6: Changing inner margin. 7.6.7 Layout On occasion, you will want to include multiple plots side-by-side or above-and-below each other. The graphical parameters mfrow and mfcol provide the simplest way to do this. Each of these requires a vector of two values, the number of rows and the number of columns. So, your vector of rows and columns should look like this: par(mfrow = c(number of rows, number of columns)) Again, this is not proper R syntax. It’s just illustrative of the idea. A real example would look like this: par(mfrow = c(3, 3)) As mentioned above, this does not plot anything. It simply tells R to do two things: first, prepare a plot layout having three rows and three columns, and second, to add plots to that layout by row. In the case of a 3x3 plot layout, that means the first plot you add will appear in the top left, the second in the top middle, the third in the top right, and so on. It will look something like this: Figure 7.7: par(mfrow = c(3, 3)) If we had used mfcol instead, plots would have been added by column, meaning the first plot would be top left, the second middle left, the third bottom left, and so on. Here is an actual example: par(pty = &quot;s&quot;, mar = rep(2, 4), mfrow = c(2, 2)) # add first plot -- top left plot(y ~ x, type = &quot;p&quot;, xlim = c(0, 1), ylim = c(0, 1)) title(main = &quot;Add first plot&quot;, adj = 0, line = 0.3, cex = 0.75) # add second plot -- top right plot(y ~ x, type = &quot;l&quot;, xlim = c(0, 1), ylim = c(0, 1)) title(main = &quot;Add second plot&quot;, adj = 0, line = 0.3, cex = 0.75) # add third plot -- bottom left plot(y ~ x, type = &quot;s&quot;, xlim = c(0, 1), ylim = c(0, 1)) title(main = &quot;Add third plot&quot;, adj = 0, line = 0.3, cex = 0.75) # add fourth plot -- bottom right plot(y ~ x, type = &quot;S&quot;, xlim = c(0, 1), ylim = c(0, 1)) title(main = &quot;Add fourth plot&quot;, adj = 0, line = 0.3, cex = 0.75) 7.7 Saving figures Alright, let’s talk about how to save figures. There are two ways to do this, one simple (this is the point-and-click approach with RStudio), the other, let’s say, less intuitive (this is the explicit code approach with R). I’m only going to outline the easy way very, very briefly because saving figures this way is inherently unreproducible, which is fine in some cases, but not when you are generating figures for scientific publications. The basic idea should be familiar enough. It’s just point-and-click. If you have a look in RStudio’s Viewer pane - this is the pane where plots are displayed by default, you’ll see a drop down menu labeled “Export.” When you click that, you’ll have the option to Save as Image… or Save as PDF…. From there, you can select the width and height of the figure, the directory to save in, the filename, and, in the case of image files, the file type (e.g., PNG, JPEG, or SVG). Click save, and you’re done! OK, so that wasn’t too bad, but now let’s talk about the reproducible way of doing the same thing, which is to declare with R code each step explicitly. First, however, we need to introduce the concept of a graphical device. In R, the phrase ‘graphical device’ refers somewhat confusingly to three different things: the software an operating system uses to display graphics on a screen or monitor, the file types used to store graphical information, and the R functions used to translate R code into the language of either the graphical software or the graphical file types. To help differentiate these, let’s refer to the latter as “graphical device functions.” There are two basic types of graphical device functions: screen and file. The first you might also call a direct device function, as it translates right away into the language your operating system uses to display graphics, for example windows() (for the Windows OS) and quartz() (for the MacOS). As suggested above, RStudio captures the results of these functions and displays them in the Viewer pane. This is helpful for getting a sense of what your figure looks like before saving to file. Importantly, you don’t have to call these functions explicitly when plotting in R. Why? Because when you first open an R session, R talks to your computer and figures out what OS you are using, so it knows implicitly what screen device function to use. The other graphical device function you might call an indirect device function, as it translate R code into an image file that you can then go on to open with whatever graphical software you have on your computer. R provides a number of file device functions, the ones you are more likely to use being pdf(), png(), jpeg() and perhaps tiff(). The procedure for using these is not obvious, but you can boil it down to these three steps: Open the graphical device. Run all your plotting code. Close the graphical device. This is more or less what the RStudio point-and-click approach is doing, though again, not in a reproducible manner. Here is how it actually looks as R code: # 1) open the graphical device png() # 2) run all your plotting code plot(y ~ x, xlim = c(0, 1), ylim = c(0, 1), xlab = &quot;X&quot;, ylab = &quot;Y&quot;) title(main = &quot;Saving a plot is weird.&quot;) # 3) close the graphical device dev.off() With the function dev.off(), ‘dev.off’ is short for “turn device off.” These graphical device functions (both screen and file) come with specific parameters you will find helpful, including all of the following: Parameter Description filename the output file path width the width of the image height the height of the image units the units in which height and width are given Applying these to our example above: # 1) open the graphical device png(filename = &quot;some_folder/my_r_plot.png&quot;, # the &quot;.png&quot; is not strictly necessary width = 5, height = 5, units = &quot;in&quot;) # in = inches # 2) run all your plotting code plot(y ~ x, xlim = c(0, 1), ylim = c(0, 1), xlab = &quot;X&quot;, ylab = &quot;Y&quot;) title(main = &quot;Saving a plot is weird.&quot;) # 3) close the graphical device dev.off() Shew! That was a lot! How about we call it a day? References "],["vector-types.html", "Chapter 8 Vector Types 8.1 Overview 8.2 Data types 8.3 Vector types 8.4 Vector display 8.5 Coercion", " Chapter 8 Vector Types 8.1 Overview Goal To familiarize students with primary data and vector types in R. tl;dr The beings of R are objects. Outcomes Here, you will learn about data types and how to create them, vector types and how to create them, and coercion methods for converting one vector or data type to another. Datasets NONE Requirements Chapter 6: R Basics Further Reading An Introduction to R (R Core Team 2020a)Advanced R (Wickham 2015) The word ‘vector’ is just fancy R-speak for an R object with a specific form or structure that contains one or more data types. The forms vectors can take include, among others, scalars and lists (see Fig. 8.1), and the data types they can hold include integer, double (i.e., fractions), logical, character, and factor (though factor is only an honorable mention). Putting effort into understanding these vector forms and data types might at first blush feel like a foolhardy pursuit of the inconsequential and esoteric, a task best relegated to crusty philosophers. But that is a mistake, for the different statistical questions you might want to ask will require data in one or the other form and type to answer. Understanding these forms and types will also help you manage your data better, thus making your statistical workflow more efficient and reproducible. 8.2 Data types R defines a number of different data types, the four primary ones being: integer, double, logical, and character, with integer and double also collectively referred to as numeric. We will not discuss any of these in great detail here, pausing only to mention very briefly what each is (Meaning), what each is for (Use), how to make one (Create), and how to catch one in the wild (Identify). As an honorable mention, we will also include factors. These are not strictly their own data type (R actually encodes them as integers), but they are ubiquitous and utilized quite often in statistical analyses. So, we’ll treat them as a data type in their own right, on a level with the others, even if they aren’t, strictly speaking. 8.2.1 Integer Meaning: A whole number or a number without a fractional component (like 1 as opposed to 1.3). Use: Counting things! It answers the question How many? Example: How many students are in this class? (Hopefully, an integer.) How many Avengers are there now? Create: By appending an L to a number. Identify: With is.integer(). my_integer &lt;- 3L my_integer ## [1] 3 is.integer(4.2) ## [1] FALSE is.integer(my_integer) ## [1] TRUE 8.2.2 Double Meaning: A number with a fractional component (like 1.3 as opposed to 1). Use: Measuring things! It answers the question How much? Example: How much coffee did I have this morning? How much did it rain last year in Pasquotank County, North Carolina? Create: By typing a number (with or without a decimal, but no L) Identify: With is.double(). my_double &lt;- 3.2 my_double ## [1] 3.2 is.double(3L) ## [1] FALSE is.double(my_double) ## [1] TRUE 8.2.3 Character Meaning: A string of symbols used to construct words in a natural language (by default, English letters). Use: Saying things! It can answer a bunch of questions. Example: How much coffee did I have this morning? How much did it rain last year in Pasquotank County, North Carolina? Create: By quoting it, i.e., surrounding a string with double \" or single ' apostrophes. Identify: With is.character(). my_character &lt;- &#39;quotidian&#39; my_character ## [1] &quot;quotidian&quot; is.character(4.2) ## [1] FALSE is.character(my_character) ## [1] TRUE A quick warning: if you do not surround the character with apostrophes, R will think you are trying to call an object with that name. If that object does not exist, R will protest. quotidian #### Error: object &#39;quotidian&#39; not found Similarly, if you use quote marks around a named object, R treats it as a character string, rather than a call to the object. &quot;my_integer&quot; ## [1] &quot;my_integer&quot; my_integer ## [1] 3 8.2.4 Logical Meaning: A truth condition, i.e., TRUE or FALSE. Also known as a boolean. Use: Implying things! Specifically, making conditional or hypothetical claims. Example: If it rains today, I will take my umbrella. If x is an integer, please add one to it. Create: By typing TRUE, FALSE, T, or F. Identify: With is.logical(). my_logical &lt;- TRUE my_logical ## [1] TRUE is.logical(my_double) ## [1] FALSE is.logical(my_logical) ## [1] TRUE You can also create logicals in R using statements that R can evaluate for their truth or falsity. For example, # is 2 greater than 5? 2 &gt; 5 ## [1] FALSE # is 7 greater than or equal to itself? 7 &gt;= 7 ## [1] TRUE # is &#39;cat&#39; the same string as &#39;hat&#39; &#39;cat&#39; == &#39;hat&#39; ## [1] FALSE The symbols &gt;, &gt;=, and == are called logical operators. We’ll talk more about them in the chapter on indexing vectors. For now, simply note that the truth conditions of statements formed with these operators can be assigned to names, as with any object in R. jim_bob &lt;- &#39;cat&#39; == &#39;hat&#39; Did you notice that our is.* functions all return a logical? 8.2.5 Factors Meaning: Categories, typically represented in R as character strings with levels. Use: Categorizing things! Example: Tom is a feline. Jerry is a mouse. Create: Using the function factor() Identify: With is.factor(). my_factor &lt;- factor(&quot;Australian&quot;) my_factor ## [1] Australian ## Levels: Australian is.factor(&quot;quotidian&quot;) ## [1] FALSE is.factor(my_factor) ## [1] TRUE Notice that unlike a simple character, a factor has “levels.” These levels are the categories of the factor variable. A good example is nationality. Nationality is a factor, with the specific levels or categories of that factor including, for instance, American, Australian, Chinese, and French. factor(c(&quot;American&quot;, &quot;Australian&quot;, &quot;Chinese&quot;, &quot;French&quot;)) ## [1] American Australian Chinese French ## Levels: American Australian Chinese French 8.3 Vector types Vectors come in two general flavors: atomic and complex. These differ in one crucial respect. While atomic vectors are limited to one data type, complex vectors can contain many data types. As shown in Fig. 8.1, atomic vectors include scalars, vectors, and matrices. Complex vectors include lists and data.frames. Figure 8.1: Vector Types. 8.3.1 Scalar A scalar-vector is an atomic vector that contains only one element. Hence, by definition, it can include only one data type. Here, we represent this with a square, which includes a value and is color-coded by its data type. Note that all the examples we have used so far have been scalar vectors. You can check this using the length() function. length(my_integer) ## [1] 1 8.3.2 Vector A vector-vector is an atomic vector that contains multiple elements. These multi-scalar atomic vectors do not really have a name like “list” or “scalar,” but in common R parlance the word ‘vector’ is often used as a synonym, which is a tad confusing, like “Are you going to New York (the state) or New York (the city)?” In what follows, we’ll just cross our fingers and hope the context is sufficient to tell the difference. The standard way to create one of these is to use the concatenate function on scalars c(). my_vector &lt;- c(1, 2, 3, 4, 5) my_vector ## [1] 1 2 3 4 5 length(my_vector) ## [1] 5 Of course, you can have a vector of any data type, it just cannot be the case that any vector contains multiple data types. integer_vector &lt;- c(1L, 2L, 3L, 4L, 5L) double_vector &lt;- c(1.1, 0.2, 3.1, 4, 5.2) character_vector &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;) logical_vector &lt;- c(TRUE, TRUE, FALSE, FALSE, TRUE) What happens if you try to create a vector with different data types? c(1, &#39;a&#39;, TRUE) ## [1] &quot;1&quot; &quot;a&quot; &quot;TRUE&quot; It converted them all to character strings! This is known as implicit coercion. It is a way of ensuring that all vector-vectors are atomic. 8.3.3 Matrix A matrix-vector is an atomic vector with dimensions, meaning the vector is “folded,” so to speak, into rows and columns. As you can see, a matrix has the shape of a data table, like what you would find in an Excel spreadsheet. To create a matrix, you use the matrix() function by providing it with a vector and then specifying the number of rows and columns it should have. my_matrix &lt;- matrix(my_vector, nrow = 2, # number of rows ncol = 3) # number of columns my_matrix ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 1 The odd, bracketed numbers printed above and to the left of the matrix are known as subscripts. They are like numeric names for columns and rows that can be used to reference specific locations in the matrix. For example, row one is [1,], and column two is [,2]. So, if I want to refer to the cell containing the value 3, use [1,2] (for more on this topic, see Chapter 10: Vector Indexing). And, if you want to know how many rows and columns a matrix has, you can use nrow() and ncol(), or the function dim(), which returns both counts. nrow(my_matrix) ## [1] 2 ncol(my_matrix) ## [1] 3 dim(my_matrix) ## [1] 2 3 8.3.4 List A list-vector is a complex vector that may include other vectors of any data type and length. The gray box around each vector in the figure below is meant to suggest that the list is a single complex vector made up of other vectors, and the space between each vector is meant to show that they are still separate components of the list, unconstrained by the other components. So, yeah, a list… To create a list, use the list() function and supply it with vectors. Be sure to assign list-names using the name = vector syntax. my_list &lt;- list(&#39;c1&#39; = c(1L, 2L, 3L, 4L), &#39;c2&#39; = double_vector, &#39;c3&#39; = c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;), &#39;c4&#39; = c(TRUE, TRUE)) my_list ## $c1 ## [1] 1 2 3 4 ## ## $c2 ## [1] 1.1 0.2 3.1 4.0 5.2 ## ## $c3 ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; ## ## $c4 ## [1] TRUE TRUE Each vector in the list is called a component. You can find the names of these components using the names() function, which returns a character vector. names(my_list) ## [1] &quot;c1&quot; &quot;c2&quot; &quot;c3&quot; &quot;c4&quot; You can also assign new names to a list with names() and the assignment arrow &lt;-. names(my_list) &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;) names(my_list) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; Now, we said above that lists can contain any vector type, and this is true. Lists can even contain other lists! my_super_list &lt;- list(&#39;e&#39; = my_list, &#39;f&#39; = my_logical) In this sense, you will sometimes hear people refer to lists as recursive vectors (R Core Team 2020a). 8.3.5 Data.frame A data.frame-vector is a special sort of list with a super-restriction on it: all the vectors it includes must be of the same length. It is also not recursive. To create a data.frame, use the data.frame() function, supplying it with name = vector arguments as you would with list(). my_dataframe &lt;- data.frame(&#39;c1&#39; = integer_vector, &#39;c2&#39; = double_vector, &#39;c3&#39; = character_vector, &#39;c4&#39; = logical_vector) my_dataframe ## c1 c2 c3 c4 ## 1 1 1.1 a TRUE ## 2 2 0.2 b TRUE ## 3 3 3.1 c FALSE ## 4 4 4.0 d FALSE ## 5 5 5.2 e TRUE Notice that when you create the data.frame, the vectors become named columns. To change or extract those column names, we can again use the names() function. names(my_dataframe) &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;) names(my_dataframe) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; As with a matrix, you can also get the number of columns and rows with nrow and ncol. nrow(my_dataframe) ## [1] 5 ncol(my_dataframe) ## [1] 4 8.4 Vector display Because lists and data.frames have complex structures with multiple data types, it’s useful to have a way to display that information in the console. One really, really useful function in that regard is str(), ‘str’ being short for “structure.” This prints slightly different information depending on whether you provide it a list or data.frame. Here is a list: str(my_list) ## List of 4 ## $ A: int [1:4] 1 2 3 4 ## $ B: num [1:5] 1.1 0.2 3.1 4 5.2 ## $ C: chr [1:3] &quot;a&quot; &quot;b&quot; &quot;c&quot; ## $ D: logi [1:2] TRUE TRUE As you can see, str() provides five critical pieces of information: the type of vector whose structure is being displayed (i.e., a list of 4) the names of the list objects (c1, c2, c3, c4), the abbreviated data type of each list object int = integer, num = number or double, chr = character, and logi = logical, the dimensions of each element (e.g., c2 is a flat, or one-dimensional, vector with five components, hence [1:5]), and the actual components of each list element (e.g., c1 consists of four values, 1, 2, 3, and 4). Here is how it looks for data.frames. str(my_dataframe) ## &#39;data.frame&#39;: 5 obs. of 4 variables: ## $ A: int 1 2 3 4 5 ## $ B: num 1.1 0.2 3.1 4 5.2 ## $ C: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... ## $ D: logi TRUE TRUE FALSE FALSE TRUE The big differences here are, first, that str() tells you that it has provided the structure of a data.frame, and, second, that it doesn’t bother to specify the dimensions of each vector in the data.frame, instead describing the number of rows (or observations) and columns (or variables). This is because of the super-restriction on data.frames, namely, that each column have the same length. One other useful function for displaying data.frames is head(), which shows the first six rows by default. head(my_dataframe) ## A B C D ## 1 1 1.1 a TRUE ## 2 2 0.2 b TRUE ## 3 3 3.1 c FALSE ## 4 4 4.0 d FALSE ## 5 5 5.2 e TRUE 8.5 Coercion R provides tools for transforming objects of one data or vector type into objects of another data or vector type. This is known as coercion, which you were introduced to above in the form of implicit coercion. As a reminder, that’s what happens when you try to combine different data types in an atomic vector like so: c(1, &#39;a&#39;, TRUE) ## [1] &quot;1&quot; &quot;a&quot; &quot;TRUE&quot; But, what about explicit coercion, meaning coercion you declare explicitly with R code? Well, R provides several functions for this, all having the form as.*() where the * is replaced with the name of the type that you wish to coerce your object to. Why care about coercion? Here are two reasons. First, you should probably care about coercion for the simple reason that you do not want to mistakenly compare apples and oranges when conducting an analysis, so you should always make sure to check the data type using the is.*() functions described above. And, if you don’t get the answer you want from those functions, use the coercion rules we are about to discuss. Second, reproducibility! An essential ingredient of reproducible code is explicit commands. As we noted above, however, R will sometimes invoke implicit coercion, with the consequence that someone who later came along to reproduce your code might for whatever reason fail to apply the coercion and, thus, fail to reproduce your results. Bad, bad, bad all around! So, bottom line, coercion matters! 8.5.1 Data type coercion Here is an example of data type coercion from integer to character. a_new_character &lt;- as.character(integer_vector) a_new_character ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; is.integer(a_new_character) ## [1] FALSE is.character(a_new_character) ## [1] TRUE As you see, it surrounds the numerals with quotation marks, indicating these are now character strings. Other data type coercion functions include as.double(), as.integer(), as.numeric() (for either double or integer), as.logical(), and as.factor(). But, notice that R can be somewhat finicky about how these behave. I mean, converting from logical, numeric, or integer to character is obvious. Just wrap the elements in quotes. But, what should R do when you ask it to convert, say, double to integer? double_vector ## [1] 1.1 0.2 3.1 4.0 5.2 as.integer(double_vector) ## [1] 1 0 3 4 5 In this case, it rounds the decimals to whole numbers, which seems intuitive enough. But, if you wanted, for example, to coerce a letter like ‘e’ into a logical value, which would it be? True or false? Obviously, this is not a meaningful question, and R agrees. Same goes for coercing character strings to numeric values. I mean, is the letter ‘b’ more like 1.2 or 57, or maybe even -33.3? as.logical(&#39;e&#39;) ## [1] NA as.integer(&#39;b&#39;) ## [1] NA As you see, R chooses not to return a value, providing NA instead. One somewhat bizarre coercion rule involves the translation of numbers into logicals, but the nature of that rule and the explanation for it are deeply esoteric topics involving R’s original design. So, rather than delving into that particular idiosyncrasy, I would just encourage you to try out as.logical() on a number (double or integer) and see what happens. Hint: try it on zero, too. 8.5.2 Vector type coercion For our purposes, the primary functions for vector type coercion are these: as.matrix(), as.list(), and as.data.frame(). Here is an example of vector type coercion from data.frame to list. a_new_list &lt;- as.list(my_dataframe) a_new_list ## $A ## [1] 1 2 3 4 5 ## ## $B ## [1] 1.1 0.2 3.1 4.0 5.2 ## ## $C ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; ## ## $D ## [1] TRUE TRUE FALSE FALSE TRUE is.data.frame(a_new_list) ## [1] FALSE is.list(a_new_list) ## [1] TRUE To round off this discussion, let me leave you with this question: how should a data.frame be coerced to a matrix? Here is an example. a_new_matrix &lt;- as.matrix(my_dataframe) a_new_matrix ## A B C D ## [1,] &quot;1&quot; &quot;1.1&quot; &quot;a&quot; &quot;TRUE&quot; ## [2,] &quot;2&quot; &quot;0.2&quot; &quot;b&quot; &quot;TRUE&quot; ## [3,] &quot;3&quot; &quot;3.1&quot; &quot;c&quot; &quot;FALSE&quot; ## [4,] &quot;4&quot; &quot;4.0&quot; &quot;d&quot; &quot;FALSE&quot; ## [5,] &quot;5&quot; &quot;5.2&quot; &quot;e&quot; &quot;TRUE&quot; is.data.frame(a_new_matrix) ## [1] FALSE is.matrix(a_new_matrix) ## [1] TRUE Remember that the cardinal rule for atomic vectors is that they consist of a single data type! References "],["workspace-management.html", "Chapter 9 Workspace Management 9.1 Overview 9.2 The workspace 9.3 The working directory 9.4 Data Import and Export", " Chapter 9 Workspace Management Figure 9.1: The R Environment 9.1 Overview Goal To introduce students to the idea of a computing workspace. tl;dr It’s just like your kitchen! Keeping it clean won’t necessarily make you a great cook, but it will make you a better one. Outcomes Here, you will learn about the workspace (as an environment), workspace management, absolute and relative file paths, the working directory, directory management, and importing and exporting data. Datasets Palmer Penguins (Horst, Hill, and Gorman 2020) Requirements Chapter 6: R BasicsChapter 8: Vector Types Further Reading NONE 9.2 The workspace When you first start working with R, you might find yourself on occasion asking a rather innocuous question: Where do the objects we create actually go? The technical answer is your computer’s memory, with an anchor (related to the object’s name) that allows you to retrieve them. The simpler and more intuitive answer is that they end up in one of your R environments, in particular, your workspace. You can think of an environment like the workspace as a special sort of named list. bob &lt;- list(a = 1:5, add_one = function(x){ x + 1 }, b = LETTERS[1:10], c = &quot;quotidian&quot;, d = TRUE) # coerce list to environment object workspace &lt;- as.environment(bob) When you create an object, you do not have to explicitly add it to an environment, for R adds your defined objects to your workspace by default. The key here is just to recognize that when you use &lt;-, you are really just adding an element to a list, the environment-list. If you want to know what objects currently reside in your workspace, you can use ls(), which works like names() does for lists, printing the names of its denizens. names(bob) ## [1] &quot;a&quot; &quot;add_one&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ls(workspace) ## [1] &quot;a&quot; &quot;add_one&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; Note that because ls() assumes you are interested in the workspace, you do not have to specify the environment explicitly. You can just do ls() instead of ls(workspace). In the example above, we chose the more verbose alternative just to emphasize the environment-as-list analogy. One other function you might find useful is ls.str(). This is a combination of ls() and str(), which you were introduced to in the previous chapter. This function lists all the elements in the workspace and provides information about their structure. ls.str(workspace) ## a : int [1:5] 1 2 3 4 5 ## add_one : function (x) ## b : chr [1:10] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; ## c : chr &quot;quotidian&quot; ## d : logi TRUE The information provided by ls() and ls.str() is more or less what you will find in RStudio’s Environment pane, by default the pane in the upper right corner of the RStudio window. That means you do not normally need to use either function. RStudio does it for you. 9.2.1 Workspace management As a general rule, you should keep your workspace clean and orderly when conducting any analysis, just as you should keep your kitchen clean and orderly when cooking. There are two big reasons for this. First, it will help prevent careless mistakes (like running operations on the wrong objects or adding a cup of salt when the recipe calls for sugar). Second, it will make it easier to manage your workflow, to make it more efficient and intelligible. Right now, I have this horrifying image of that college roommate, you know, the one that never does the dishes, leaves food stains on the counter, lets food rot in the fridge, and for some reason you can’t quite fathom, spends several weeks conducting an experiment involving molds growing beneath the sink. And now that person is somehow, by some miracle, in charge of - I don’t know - Katz’s Deli in New York! One shudders at the thought! I mean, talk about a kitchen nightmare. By all that is good, you ought to avoid this. You want to avoid workspace nightmares. One way to do that is to regularly remove objects that you will not re-use - meaning, you should banish them from your workspace. This is achieved with the rm() or remove function. rm(a, envir = workspace) # read this as: remove object a from the workspace ls(workspace) ## [1] &quot;add_one&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; Just as we noted with ls(), when you’re removing objects from your workspace (and not the toy environment that I just created as an example), it is sufficient to type rm(&lt;object&gt;) without specifying the environment, since it defaults to the workspace anyway. List objects provide another really useful tool for workspace management, though their utility might not be as obvious to R users early in their career. A very common use case involves data objects that have different values but share identical structures (like data.frames with the same number of columns, all having the same names). This will happen, for example, when you are doing bootstrap resampling or simulations and want to generate a new model for each set of data. There are more sophisticated ways to manage such data, but a list is a good option too. Rather than having, say, ten thousand unique data.frames in your R environment, you have a single list to hold them all. 9.3 The working directory Now that we have some sense of the workspace in R, we need some way to associate it with a particular location on your computer. Why? For the familiar reasons: (i) to make your workflow more efficient (mostly by saving you from the tedium of excessive typing!) and (ii) to make your workflow more reproducible! And, actually, we can add one other very big one with very immediate, practical consequences, namely, (iii) to make collaboration easier! To make these big claims more digestible, let’s talk about file paths, and in particular the distinction between relative and absolute file paths. 9.3.1 File paths A file path, maybe you know, is just a way of specifying the location of a file in a hierarchical directory. If you think of that hierarchical directory as having a tree-like structure, you can represent it as we do in Fig. 9.2. Figure 9.2: Tree-like structure of a hierarchical computer directory. The orange line represents the absolute file path to data.csv. A complete file path for data.csv here might look like this: ROOT/Users/Leslie/NPS_project_folder/data.csv with the backslash / providing a folder or directory separator, signifying that the bit on the right-hand side is contained within the bit on the left-hand side (sometimes called the “parent” directory). Assuming that ROOT is the first or top-most directory in this system (meaning it’s not a sub-folder of some other folder or directory), that file path is also absolute. No matter where you are on your computer, using that file path will also pick out that specific data.csv file. A relative file path, on the other hand, is one that depends on your current location on your computer. It is relative to that location. For instance, the relative file path NPS_project_folder/data.csv will find data.csv only if your current location on your computer is ROOT/Users/Leslie As you can see, if we take care to make our location known, relative file paths can save us a lot of typing. They also contribute to reproducibility, but let’s build up to that idea. 9.3.2 Setting the working directory First, let’s consider what happens if you try to use relative file paths in R without specifying what directory you are currently working in. So, let’s look more carefully at the folders in Leslie’s user directory. Figure 9.3: Leslie has two folders in her directory on the computer: (i) scrap_book_folder and (ii) NPS_project_folder. She wants to read the file data.csv into R, but something has gone wrong… From the diagram, you can see that her scrap_book_folder contains, among other things, some image and audio files. Similarly, NPS_project_folder includes some text and data files, as well as an R script! Now, suppose Leslie wants to open the file NPS_project_folder/data.csv in R and assign it to a name using this line of code: dat &lt;- read.csv(&quot;data.csv&quot;) What happens? It throws an error! R says it cannot open a connection because the file or directory does not exist. Why is this? The simple answer is that data.csv is a relative path, but R is currently pointing to the scrap_book_folder, so it’s looking in there for that file. Assuming we want to avoid absolute file paths - hint: we do! - we need some way to point R to NPS_project_folder, so we can use the relative path data.csv. To help with this, base R provides two functions: getwd() and setwd(). As you might have guessed, the first identifies or gets the current working directory, the second changes or sets it. If Leslie were to use these commands while working with R on her own computer, she could type this: getwd() ## [1] &quot;ROOT/Users/Leslie/scrap_book_folder&quot; setwd(&quot;ROOT/Users/Leslie/NPS_project_folder&quot;) getwd() ## [1] &quot;ROOT/Users/Leslie/NPS_project_folder&quot; Having set the working directory to NPS_project_folder, she could now go on to using the relative path data.csv to import that data into R. 9.3.3 Reproducible projects What makes code reproducible? While we can’t give a complete answer to that now, we can offer at least one necessary condition: R code is reproducible only if it is self-contained. What does it mean for R code to be self-contained? Putting it simply, you should be able to save your R script (or the folder containing it, along with any data it requires) onto an external thumb drive, load it onto another computer (even one with a different operating system), run all the code, and get the exact (or very nearly the same) results WITHOUT CHANGING ANYTHING in the script. This definition of containment should give you some sense of the problem setwd() poses. While it does allow you to use relative file paths in whatever comes after it, it itself requires an absolute file path! Meaning, each time you load the script onto a different computer, to run the code, you have to update setwd() with a new absolute path to the working directory. Thus, it bakes in an inherently unreproducible element of code. What is the solution to this? In a word, Projects, specifically RStudio projects. For a passionate and sometimes humorous defense of RStudio Projects as an alternative to setwd(), see Jenny Bryan’s somewhat infamous blog post, Project-oriented workflow. What is a project? It’s two things, really: a folder and a file. When you create a project in RStudio, you first give it a name. This name is then assigned to the project folder, which holds a project file that also has that name. You can identify the project file because it has a .Rproj extension. Whenever you open the project in RStudio, RStudio finds the absolute file path to the folder containing the .Rproj file and sets it as the working directory. I won’t go into detail about how to make one. The basic steps are to open RStudio, then click File &gt; New Project and make suitable choices based on the prompts. You’ll almost certainly want to choose an Empty Project to begin with. And make sure to save it in a directory you will remember with a name that that clearly expresses the purpose of the project. 9.3.4 Directory management Every research project is different, but some common elements to tend to holdover. For instance, you will typically have some empirical inputs (meaning, your data), outputs (like figures), and because you are working with R, you will also have R scripts (and probably even Rmarkdown documents, though we are not discussing those here). These common elements should suggest a useful structure (shown in Fig. 9.4) that you will want to return to again and again for your project directory. Namely, it should have a data folder (where you include your hard won empirical observations), a figures folder (any that you might want to share with collaborators, include in publications, or use as a tool for communicating with the public), and a scripts or R folder (where you will include all the scripts that you write for your analysis). Figure 9.4: Recommended directory structure includes subfolders for data, scripts, and figures. Naming Conventions Here are a few - somewhat opinionated - rules of thumb for naming files and folders: Make the name super descriptive. For example, if you have an R script that you write to process spatial data before conducting some analysis, call it process_spatial_data.R. Do not use empty spaces! This is a big one. In several contexts, like URL file paths, spaces will break paths. For instance, if you go to download “bob.com/my resume.pdf”, you’ll end up with a file called “my.” To avoid these sorts of issues, you should use underscores _ and dashes - in place of spaces. Above all else, though, BE CONSISTENT with your naming conventions. Believe me when I say this, it will save you a lot of heartache in the long run. 9.4 Data Import and Export Consider this scenario: you’ve gone out to the field, perhaps working with Dr. Kristen Gorman at Palmer Station in Antarctica. While there, you collect a heroic number of observations on the native penguin species, which you document meticulously (probably writing it down on paper, though that’s starting to change). Now, back home, you find yourself sitting at your computer, wanting to model your precious in R. Obviously, it will not do to prostrate yourself before your computer, holding up your field notes in pious supplication. Your computer - at least as of the writing of this sentence - won’t even acknowledge your presence. So, you’ll have to do it yourself. To that end, you’ll first want to digitize your data, probably using a spreadsheet application like Excel. And, because you have foresight, you’ll decide to save your data to a comma-separated values (or .csv) file. At this point, perhaps fortunately, you’ve now completed the lion’s share of your research project (I’d put it around 70-75%), but you’re still not done! To make that beautiful model in R, you’ll need to get your data into R first. OK, so what do we do here? 9.4.1 Read and write tables Notice, to begin with, that we are talking about tabular or rectangular data, likely consisting of varying data types. This should clue you into the vector type that you will be creating in R. Hint: it rhymes with data.frame. Notice, too, that we are talking about a comma-separated values file. What does that mean, exactly? Basically, it refers to a plain text file format in which columns of data are separated by commas. Consider, for example, your penguins data, which you’ve saved to a file called penguins.csv. Here is how the first six lines should look when opened with your operating system’s text editor: &quot;species&quot;,&quot;island&quot;,&quot;bill_length_mm&quot;,&quot;flipper_length_mm&quot;,&quot;body_mass_g&quot;,&quot;sex&quot;,&quot;year&quot; &quot;Adelie&quot;,&quot;Torgersen&quot;,39.1,181,3750,&quot;male&quot;,2007 &quot;Adelie&quot;,&quot;Torgersen&quot;,39.5,186,3800,&quot;female&quot;,2007 &quot;Adelie&quot;,&quot;Torgersen&quot;,40.3,195,3250,&quot;female&quot;,2007 &quot;Adelie&quot;,&quot;Torgersen&quot;,NA,NA,NA,NA,2007 &quot;Adelie&quot;,&quot;Torgersen&quot;,36.7,193,3450,&quot;female&quot;,2007 As you can see, the first line of text, known as the header, specifies the column names, and the following lines indicate the actual rows of data, which are separated into columns with commas. Some other column separators you might encounter from time to time include semi-colon (;, which is more common in countries that use the comma as decimal place, though it also uses the .csv file extension) and tabs (or a specific number of blank spaces, with file extension .tsv). To import these delimited text files of tabular data, R provides the function read.table(). To work with this function, you need to familiarize yourself with three key parameters: file, sep, and header. * The value you supply to file is the path to the data file, which you rightly stored in the data folder of your RStudio project directory, so that the path is relative. You’ll want to provide this as a character string, meaning you need to enclose it in quotation marks: file = \"data/penguins.csv\". * The sep parameter wants to know what separator is being used to signal columns. In this case, it’s a comma, which you’ll also want to supply as a character string: sep = \",\". * Finally, you’ll want to specify whether the first line of text is a header or not (sometimes they are not included). This you will give a logical value (TRUE if the header exists, FALSE otherwise): header = TRUE. All together then, you will want to write this: penguins &lt;- read.table(file = &quot;data/penguins.csv&quot;, sep = &quot;,&quot;, header = TRUE) making sure to assign the imported data to a name so that it sticks around. When writing an R script for analysis (as opposed to, say, data management), you should strive as far as possible to load all necessary data at the beginning. Do not rely on reading and writing intermediate results in the middle of your workflow as this will potentially compromise the reproducibility of your analysis. What about exporting data out of R? For that, you’ll use write.table(). This function more or less mirrors read.table(), but requires that you also specify what data.frame you are wanting to save to file. So, supposing you’ve done some processing of your penguins data, added columns perhaps or filtered rows, and assigned the new data.frame to penguins_new, you’ll do something like this: write.table(penguins_new, file = &quot;data/penguins_new.csv&quot;, sep = &quot;,&quot;, row.names = FALSE) Just ignore row.names in this function call. It’s an odd design choice on the part of the authors of R that you don’t need to understand, though do remember to ALWAYS set it to FALSE. If you deal with comma-separated text files regularly, you might prefer read.csv() and write.csv(), which are wrappers around read.table() and write.table() that set sep = \",\" and header = TRUE by default. 9.4.2 Read and save objects The authors of R have defined a few R-specific file types, but let’s just focus on one, .Rds. This format allows you to save a single R object to file. The functions for reading and writing these file types are saveRDS() and readRDS(). You use these basically the same way you use read.table() and write.table(). saveRDS(penguins, file = &quot;data/penguins.Rds&quot;) penguins &lt;- readRDS(&quot;data/penguins.Rds&quot;) There are few occasions when you will use these, but when you do, they will typically be to save or restore non-rectangular or non-tabular data objects like lists and models. Some other related functions include load() and save(), which allow you to save multiple R objects at once, and load.image() and save.image(), which allow you to save and restore all the R objects in your current working environment. However, you should not rely on these. In fact, don’t use them. Why? Because this will force you to write R scripts that are reproducible! References "],["subsetting-data.html", "Chapter 10 Subsetting Data 10.1 Overview 10.2 Selecting variables 10.3 Filtering observations 10.4 Filtering and selecting 10.5 Formiddable subsetting 10.6 Index vectors 10.7 Subset output", " Chapter 10 Subsetting Data 10.1 Overview Goal To understand how to subset data in R. tl;dr Like when you use your index finger to point at something. Outcomes Here, you will learn about the friendly subset() function and the foreboding subset operators [ and $. Datasets Palmer Penguins (Horst, Hill, and Gorman 2020) Requirements Chapter 6: R Basics Further Reading NONE Consider these three scenarios: You have a global dataset detailing movie theater attendance rates, along with movie genre and director, for the last decade, but you only want to compare general attendance trends in Brazil to those in, say, France. You have an enormous pollen record for Western North America going back some 15,000 years, but you’re only interested in the terminal Pleistocene (approximately 11,000 to 10,000 years ago). You have measurements of multiple penguin traits across several species, but you only want to model the relationship of bill length to body mass for Adelie penguins living on Torgersen Island. In all of these scenarios, you are required to extract from the total data just the portion relevant to your specific research question. This is known as subsetting. It comes in two primary flavors: (i) selecting variables or columns by their name or numeric position and (ii) filtering observations or rows according to the values of one or more variables. While R provides many tools and methods for subsetting data in these ways, we will focus on the subset() function, which provides a friendly interface to handling tabular data or data.frames. We will also cover the sparser bracket [ and dollar $ operators, which provide greater flexibility, albeit with a much more formidable syntax. We’ll be working again with our familiar penguins data. penguins &lt;- read.csv(&quot;penguins.csv&quot;) str(penguins) ## &#39;data.frame&#39;: 344 obs. of 7 variables: ## $ species : chr &quot;Adelie&quot; &quot;Adelie&quot; &quot;Adelie&quot; &quot;Adelie&quot; ... ## $ island : chr &quot;Torgersen&quot; &quot;Torgersen&quot; &quot;Torgersen&quot; &quot;Torgersen&quot; ... ## $ bill_length_mm : num 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ flipper_length_mm: int 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : chr &quot;male&quot; &quot;female&quot; &quot;female&quot; NA ... ## $ year : int 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... 10.2 Selecting variables Subsetting data by selecting variables is fairly straightforward with subset(). You simply pass the name of each column you want to the function’s select parameter. Here are some examples. Select one variable penguins_subset &lt;- subset(penguins, select = island) head(penguins_subset) ## island ## 1 Torgersen ## 2 Torgersen ## 3 Torgersen ## 4 Torgersen ## 5 Torgersen ## 6 Torgersen Select multiple variables penguins_subset &lt;- subset(penguins, select = c(species, island, body_mass_g)) head(penguins_subset) ## species island body_mass_g ## 1 Adelie Torgersen 3750 ## 2 Adelie Torgersen 3800 ## 3 Adelie Torgersen 3250 ## 4 Adelie Torgersen NA ## 5 Adelie Torgersen 3450 ## 6 Adelie Torgersen 3650 10.3 Filtering observations Subsetting data by filtering observations is a little bit more involved, but intuitively, you are simply asking for those observations that satisfy a certain condition. Getting subset() to return those observations requires that you pass an expression containing a comparison operator to the function’s eponymous subset parameter. The expression is then evaluated by R for its truth or falsity, with observations that evaluate to TRUE being returned, observations that evaluate to FALSE being ignored. Let’s walk through an example, then try to break down what is happening in a little more detail. Suppose we want only those observations of penguins residing on Biscoe Island. Here is how we would go about collecting those observations from our penguins data.frame. biscoe_penguins &lt;- subset(penguins, subset = (island == &quot;Biscoe&quot;)) head(biscoe_penguins) ## species island bill_length_mm flipper_length_mm body_mass_g sex year ## 21 Adelie Biscoe 37.8 174 3400 female 2007 ## 22 Adelie Biscoe 37.7 180 3600 male 2007 ## 23 Adelie Biscoe 35.9 189 3800 female 2007 ## 24 Adelie Biscoe 38.2 185 3950 male 2007 ## 25 Adelie Biscoe 38.8 180 3800 male 2007 ## 26 Adelie Biscoe 35.3 187 3800 female 2007 Here we supplied this key information to the subset() function: subset = (island == &quot;Biscoe&quot;) with the additional parentheses provided only for readability, not because they are required. What does this expression mean exactly? In effect, it is directing subset() to scan through our data, specifically the island column, and select only those rows where the value is Biscoe. That’s island == \"Biscoe\". The so-called comparison operator here is the double equal sign, ==. This is importantly different than the single equal sign, =, which is used inside a function as part of a key=value or argument=value pair. R provides several helpful comparison operators: == for equals in the sense of a perfect match, != for not equals, &gt; for greater than, &gt;= for greater than or equal to, &lt; for less than, and &lt;= for less than or equal to. You can use the first two, == and !=, for comparisons with either character or numeric variables (integer or double), but the rest apply only to the latter. Let’s run through a few more examples: Filter penguins with body mass greater than 3500 grams. larger_penguins &lt;- subset(penguins, subset = (body_mass_g &gt; 3500)) head(larger_penguins) ## species island bill_length_mm flipper_length_mm body_mass_g sex year ## 1 Adelie Torgersen 39.1 181 3750 male 2007 ## 2 Adelie Torgersen 39.5 186 3800 female 2007 ## 6 Adelie Torgersen 39.3 190 3650 male 2007 ## 7 Adelie Torgersen 38.9 181 3625 female 2007 ## 8 Adelie Torgersen 39.2 195 4675 male 2007 ## 10 Adelie Torgersen 42.0 190 4250 &lt;NA&gt; 2007 Filter penguins with beaks longer than 39 millimeters. long_beaks &lt;- subset(penguins, subset = (bill_length_mm &gt; 39)) head(long_beaks) ## species island bill_length_mm flipper_length_mm body_mass_g sex year ## 1 Adelie Torgersen 39.1 181 3750 male 2007 ## 2 Adelie Torgersen 39.5 186 3800 female 2007 ## 3 Adelie Torgersen 40.3 195 3250 female 2007 ## 6 Adelie Torgersen 39.3 190 3650 male 2007 ## 8 Adelie Torgersen 39.2 195 4675 male 2007 ## 10 Adelie Torgersen 42.0 190 4250 &lt;NA&gt; 2007 10.3.1 Multiple conditions Often enough, we will want to combine a number of these simple conditions into one complex expression. In R, this is done with Boolean operators: &amp; for and, | for or, and ! for not. To demonstrate the underlying logic of these Boolean operators, consider these shapes and colors. You can think of each of A, B, and C as its own observation or row in a data.frame that includes two variables color and shape. Boolean Subset Result x color == \"yellow\" A, B y shape == \"circle\" B, C x &amp; y color == \"yellow\" &amp; shape == \"circle\" B x | y color == \"yellow\" | shape == \"circle\" A, B, C x &amp; !y color == \"yellow\" &amp; shape != \"circle\" A !x &amp; y color != \"yellow\" &amp; shape == \"circle\" C !(x &amp; y) !(color == \"yellow\" &amp; shape == \"circle\") A, C !(x | y) !(color == \"yellow\" | shape == \"circle\") NULL And here is an example with our penguins data.frame, where we ask R to return those observations in which (a) penguins reside on Biscoe Island and (b) their bills are longer than 39 millimeters. biscoe_long_beaks &lt;- subset(penguins, subset = (island == &quot;Biscoe&quot; &amp; bill_length_mm &gt; 39)) head(biscoe_long_beaks) ## species island bill_length_mm flipper_length_mm body_mass_g sex year ## 27 Adelie Biscoe 40.6 183 3550 male 2007 ## 28 Adelie Biscoe 40.5 187 3200 female 2007 ## 30 Adelie Biscoe 40.5 180 3950 male 2007 ## 51 Adelie Biscoe 39.6 186 3500 female 2008 ## 52 Adelie Biscoe 40.1 188 4300 male 2008 ## 54 Adelie Biscoe 42.0 200 4050 male 2008 10.4 Filtering and selecting subset() also allows you to filter observations and select rows at the same time. biscoe_long_beaks &lt;- subset(penguins, subset = (island == &quot;Biscoe&quot; &amp; bill_length_mm &gt; 39), select = c(species, island, bill_length_mm)) head(biscoe_long_beaks) ## species island bill_length_mm ## 27 Adelie Biscoe 40.6 ## 28 Adelie Biscoe 40.5 ## 30 Adelie Biscoe 40.5 ## 51 Adelie Biscoe 39.6 ## 52 Adelie Biscoe 40.1 ## 54 Adelie Biscoe 42.0 In this example, we filter observations to include only penguins that (a) reside on Biscoe Island and (b) have a bill length longer than 39 millimeters. We also select only the species, island, and bill_length_mm variables. 10.5 Formiddable subsetting Selecting variables and filtering rows can also be done with the bracket [ operator. This is a less friendly tool in many ways, but it is more flexible, meaning you can subset a data.frame in more ways than you can with the subset() function. What is more, understanding it, and especially the concept of an index vector, should help us better understand the use of subset() too. So, let’s first walk through an example of how to subset a data.frame. Then we’ll break down what we’re doing in more detail. The basic syntax is this: dataframe[row, column] where dataframe is the name of your dataframe, row is an index vector of the filtered observations, and column is an index vector of the selected variables. As you see, the closed [ operator flanks the row and column indexes, which are separated by a comma. Here is an actual example with penguins: # i for index row_i &lt;- 1:5 col_i &lt;- 1:3 penguins[row_i, col_i] ## species island bill_length_mm ## 1 Adelie Torgersen 39.1 ## 2 Adelie Torgersen 39.5 ## 3 Adelie Torgersen 40.3 ## 4 Adelie Torgersen NA ## 5 Adelie Torgersen 36.7 This code filters the first five observations in the penguins data and selects the first three variables. The key to understanding this is to understand the concept of an index vector. 10.6 Index vectors You should already be familiar with index vectors. That is actually what we were constructing when, for example, we supplied subset = (bill_length_mm &gt; 39) to subset(). These are known specifically as logical index vectors, for they include TRUE and FALSE values. The greater flexibility of [ comes from the fact that you can supply it an index vector defined by any data type, not just logical vectors as subset() requires. That said, the three that are most useful (and the three that you will use most often) are: Integer, which indexes by position, Character, which indexes by name, and Logical, which indexes by condition, as you learned above. Let’s walk through some examples of each. 10.6.1 Integer index With integer indexing, you select variables and filter rows by their literal numeric position. This is actually what we used in our example just above. The basic idea is to supply the [ operator with a vector of integers for rows or observations and a vector of integers for columns or variables. row_i &lt;- c(2, 4, 6, 8, 10) col_i &lt;- c(1, 3, 5) penguins[row_i, col_i] ## species bill_length_mm body_mass_g ## 2 Adelie 39.5 3800 ## 4 Adelie NA NA ## 6 Adelie 39.3 3650 ## 8 Adelie 39.2 4675 ## 10 Adelie 42.0 4250 For brevity, we can supply the indexing vectors directly. penguins[c(2, 4, 6, 8, 10), c(1, 3, 5)] ## species bill_length_mm body_mass_g ## 2 Adelie 39.5 3800 ## 4 Adelie NA NA ## 6 Adelie 39.3 3650 ## 8 Adelie 39.2 4675 ## 10 Adelie 42.0 4250 And, this is usually fine if the subsetting you are doing is quite simple. For more complex cases, you should stick to creating the indexing vectors first. Because these are numbers, R allows us to perform arithmetic operations on them (like addition and subtraction) to produce new vectors. (Note that the parentheses are not necessary and are only added to increase readability.) (row_i &lt;- (row_i - 1)) ## [1] 1 3 5 7 9 (col_i &lt;- (col_i + 1)) ## [1] 2 4 6 penguins[row_i, col_i] ## island flipper_length_mm sex ## 1 Torgersen 181 male ## 3 Torgersen 195 female ## 5 Torgersen 193 female ## 7 Torgersen 181 female ## 9 Torgersen 193 &lt;NA&gt; Finally, if we want everything but some value or values, we simply negate the vectors with the dash, -. # remove these specific columns penguins[row_i, -col_i] ## species bill_length_mm body_mass_g year ## 1 Adelie 39.1 3750 2007 ## 3 Adelie 40.3 3250 2007 ## 5 Adelie 36.7 3450 2007 ## 7 Adelie 38.9 3625 2007 ## 9 Adelie 34.1 3475 2007 10.6.2 Character index With character indexing, you reference objects by their given name. With data.frames, this is most useful for selecting variables. row_i &lt;- 1:5 col_i &lt;- c(&quot;species&quot;, &quot;island&quot;, &quot;body_mass_g&quot;) penguins[row_i, col_i] ## species island body_mass_g ## 1 Adelie Torgersen 3750 ## 2 Adelie Torgersen 3800 ## 3 Adelie Torgersen 3250 ## 4 Adelie Torgersen NA ## 5 Adelie Torgersen 3450 If we want to extract a single variable as a vector from a data.frame, we can also use the $ operator, which does not require you to quote the variable name. Because the $ operator returns a single vector, we can also do simple indexing on it too. body_mass_g &lt;- penguins$body_mass_g body_mass_g[1:5] ## [1] 3750 3800 3250 NA 3450 10.6.3 Logical index To illustrate what our logical index vectors are doing in subset() and [, let’s look at the first five values of body_mass_g from the penguins data and suppose, perhaps, that we want to return only those penguins having a body mass greater than 3500 grams. body_mass_g &lt;- c(3750, 3800, 3250, NA, 3450, 3650) body_mass_g &gt; 3500 ## [1] TRUE TRUE FALSE NA FALSE TRUE As you see, R compares every value in body_mass_g to 3500. If the value is greater than 3500, it returns TRUE. If it is less than 3500, it returns FALSE. And NA returns NA. In subset(), these logical values are then used to decide which observations to filter. As mentioned above, observations or rows in which the comparison evaluates to TRUE are returned, those that evaluate to FALSE or NA are ignored. Combining this idea with the use of the $ operator, we can subset using [ in this way: # extract body mass variable as vector body_mass_g &lt;- penguins$body_mass_g # construct logical index vector with it row_i &lt;- (body_mass_g &gt; 3500) # select variables col_i &lt;- c(&quot;species&quot;, &quot;island&quot;, &quot;body_mass_g&quot;) # subset penguins penguins_subset &lt;- penguins[row_i, col_i] head(penguins_subset) ## species island body_mass_g ## 1 Adelie Torgersen 3750 ## 2 Adelie Torgersen 3800 ## NA &lt;NA&gt; &lt;NA&gt; NA ## 6 Adelie Torgersen 3650 ## 7 Adelie Torgersen 3625 ## 8 Adelie Torgersen 4675 Here, we subset the penguins data by penguins having a body mass greater than 3500 grams and select the variables species, island, and body_mass_g. You can also use these in subset(). This is especially useful when your filter expression includes a very complex comparison. # multiple conditions ind_1 &lt;- (penguins$body_mass_g &gt; 3500) ind_2 &lt;- (penguins$island == &quot;Biscoe&quot;) ind_3 &lt;- (penguins$bill_length_mm &gt; 50) # combined with Booleans into one row index row_i &lt;- (ind_1 &amp; ind_2) | ind_3 # select variables col_i &lt;- c(&quot;species&quot;, &quot;island&quot;, &quot;body_mass_g&quot;) penguins_subset &lt;- subset(penguins, subset = row_i, filter = col_i) head(penguins_subset) ## species island bill_length_mm flipper_length_mm body_mass_g sex year ## 22 Adelie Biscoe 37.7 180 3600 male 2007 ## 23 Adelie Biscoe 35.9 189 3800 female 2007 ## 24 Adelie Biscoe 38.2 185 3950 male 2007 ## 25 Adelie Biscoe 38.8 180 3800 male 2007 ## 26 Adelie Biscoe 35.3 187 3800 female 2007 ## 27 Adelie Biscoe 40.6 183 3550 male 2007 10.6.4 Empty index For completeness, we should also mention that an empty vector will simply return unchanged whatever you are subsetting with it. This is not particularly useful when applied to simple atomic vectors, but it does save some typing when applied to data.frames and other vector types with dimensions. It saves typing by allowing you to leave unspecified the row index to return all rows and column index to return all columns. col_i &lt;- c(&quot;species&quot;, &quot;island&quot;, &quot;body_mass_g&quot;) # empty space or empty vector for rows penguins_subset &lt;- penguins[ , col_i] # does it return all rows? nrow(penguins_subset) == nrow(penguins) ## [1] TRUE row_i &lt;- 1:10 # empty space or empty vector for columns penguins_subset &lt;- penguins[row_i, ] # does it return all columns? ncol(penguins_subset) == ncol(penguins) ## [1] TRUE 10.7 Subset output While subset() always returns a data.frame, filtering rows and subsetting variables with [ will return a different vector type depending on whether you are subsetting it with one or more columns. We can represent these outcomes as a 2x2 contingency matrix, with the value in each cell indicating the resulting vector If you select one variable, [ will return a vector, and if you select multiple variables, it will return a data.frame. If you recall that an atomic vector can have only one value, these rules should make sense to you. A column just is a vector with a single set of values, so indexing a single column should return a vector. However, a row cuts across vectors, potentially including multiple data types, so R has a choice to either coerce them all to the same data type and return a vector or keep the data types different and return a smaller data.frame. The latter is the safer alternative, so it makes sense. Single column → vector row_i &lt;- 1:5 col_i &lt;- 3 penguins[row_i, col_i] ## [1] 39.1 39.5 40.3 NA 36.7 Multiple columns → data.frame row_i &lt;- 1:5 col_i &lt;- 3:5 penguins[row_i, col_i] ## bill_length_mm flipper_length_mm body_mass_g ## 1 39.1 181 3750 ## 2 39.5 186 3800 ## 3 40.3 195 3250 ## 4 NA NA NA ## 5 36.7 193 3450 References "],["transforming-data.html", "Chapter 11 Transforming data 11.1 Overview 11.2 Order", " Chapter 11 Transforming data Figure 4.1: Artwork by Allison Horst contributed to Hadley Wickham’s talk “The Joy of Functional Programming (for Data Science).” 11.1 Overview Goal To teach students how to transform raw tabular data to make it suitable for statistical analysis. tl;dr Wrangling data is challenging in any context, but at least it’s reproducible in R. Outcomes Here, you will learn about arranging data.frames by ordering along one or more variables or columns, subsetting data.frames by filtering rows and selecting columns, transforming data.frames by adding or changing variable or column values, summarizing data.frames by aggregating factor variables, and combining data.frames by binding rows and/or columns. Datasets Palmer Penguins (Horst, Hill, and Gorman 2020) Requirements NONE Further Reading NONE Data wrangling refers to all the work you do to prepare your data for analysis in R. Typically, this involves getting your data into R, making sure it’s in the right shape or format, making sure you have the right variables and observations, and changing those to fit the analysis where needed. The first of these we already covered in Chapter 9: Workspace Management. Here, we will focus on the latter aspects of data wrangling, specifically subsetting and transforming data. While these are far less glamorous than other parts of a statistical workflow, they are no less important. They will also gobble up the greater part of your research effort, even when done efficiently. So, we will spend quite a bit of time on these aspects of data wrangling. Please note that the focus here will be on wrangling data.frames. 11.2 Order Let’s start with something simple like changing the order of rows in a data.frame. For this, we’ll use our penguins data. penguins &lt;- read.csv(&quot;penguins.csv&quot;) str(penguins) ## &#39;data.frame&#39;: 344 obs. of 7 variables: ## $ species : chr &quot;Adelie&quot; &quot;Adelie&quot; &quot;Adelie&quot; &quot;Adelie&quot; ... ## $ island : chr &quot;Torgersen&quot; &quot;Torgersen&quot; &quot;Torgersen&quot; &quot;Torgersen&quot; ... ## $ bill_length_mm : num 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ flipper_length_mm: int 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : chr &quot;male&quot; &quot;female&quot; &quot;female&quot; NA ... ## $ year : int 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... Suppose we want to re-arrange the rows of this data.frame by sorting them from the smallest penguin to the largest. One would prefer that base R provide a simple function that does this for us. Ideally, it would take a data.frame as input, along with a specification of which variable or variables should be used to re-order rows, and return the re-ordered data.frame as output. Unfortunately, that does not exist, not in base R anyway. So, ordering a data.frame requires some finagling. Specifically, you need to create an index vector of the re-ordered rows and apply that to the data.frame. To create such a vector, we use the order() function. To see how this work: # create index vector i &lt;- order(df$c1, decreasing = FALSE) #### Error in df$c1: object of type &#39;closure&#39; is not subsettable df$c1 #### Error in df$c1: object of type &#39;closure&#39; is not subsettable i #### Error: object &#39;i&#39; not found df[i, ] #### Error: object &#39;i&#39; not found Note, that you can order by increasing values of the variable (decreasing = FALSE) or decreasing values of the variable (increasing = TRUE). i &lt;- order(df$c1, decreasing = TRUE) #### Error in df$c1: object of type &#39;closure&#39; is not subsettable i #### Error: object &#39;i&#39; not found df[i, ] #### Error: object &#39;i&#39; not found 11.2.1 Change [transform()] 11.2.2 Combine References "],["whatisstats.html", "Chapter 12 What is Statistics?", " Chapter 12 What is Statistics? \\[ \\begin{aligned} y &amp;= E(y) + \\epsilon \\\\ E(y) &amp;= mu \\\\ \\epsilon &amp;\\sim N(0, sigma) \\\\ \\end{aligned} \\] I like this because it is modular. You can use this to explain: - what does E(y) mean? It’s the expected value or what you would guess as the value for any new observation of y. Why is it constant? Well, we don’t have any other information to control how it varies. o Now it’s a short step to add in X. And the nice thing is that you only now have to change the E(y) definition to E(y) = beta X. - What does sigma mean? It’s a measure of how much observed y varies around mu. We don’t know exactly what this variation might be, but we can try to quantify the range of errors. o Better yet, we don’t just say that the variation is between +/- sigma, but that there is probability of errors, which is higher closer to mu, and then drops off away from it. o It’s easy then to change the description of the errors. We’ve used a normal distribution, but if your data don’t match this, you can change N(0, sigma) to Pois(lambda), or Binom(pi) giving you a GLM. (You need a link function as well, but that’s pretty straightforward) o You can use this to explain iid – why is the 0 important in the errors? It’s so that the errors are unbiased (which they should be), and that these are symmetric with a normal distribution - Other things: o You can explain heteroscedascity by changing sigma to sigma_i o Mixed models change sigma to sigma_j (where j is the group membership) o Temporal or spatial models just alter sigma to two components, u and v, and then you can start to explain how you model u (the spatial error). "],["univariate-description.html", "Chapter 13 Univariate Description", " Chapter 13 Univariate Description "],["probability-distributions.html", "Chapter 14 Probability Distributions", " Chapter 14 Probability Distributions "],["inference-tests.html", "Chapter 15 Inference Tests", " Chapter 15 Inference Tests "],["multivariate-description.html", "Chapter 16 Multivariate Description", " Chapter 16 Multivariate Description "],["ols.html", "Chapter 17 Linear Models", " Chapter 17 Linear Models "],["model-diagnostics.html", "Chapter 18 Model Diagnostics", " Chapter 18 Model Diagnostics "],["glm.html", "Chapter 19 Generalized Linear Models", " Chapter 19 Generalized Linear Models "],["references.html", "References", " References "]]
